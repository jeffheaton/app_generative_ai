{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whjsJasuhstV"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_04_5_coder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euOZxlIMhstX"
      },
      "source": [
        "# T81-559: Applications of Generative Artificial Intelligence\n",
        "**Module 4: LangChain: Chat and Memory**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Yov72PhstY"
      },
      "source": [
        "# Module 4 Material\n",
        "\n",
        "* Part 4.1: LangChain Conversations [[Video]]() [[Notebook]](t81_559_class_04_1_langchain_chat.ipynb)\n",
        "* Part 4.2: Conversation Buffer Window Memory [[Video]]() [[Notebook]](t81_559_class_04_2_memory_buffer.ipynb)\n",
        "* Part 4.3: Chat with Summary and Fixed Window [[Video]]() [[Notebook]](t81_559_class_04_3_summary.ipynb)\n",
        "* Part 4.4: Chat with Persistence, Rollback and Regeneration [[Video]]() [[Notebook]](t81_559_class_04_4_persistence.ipynb)\n",
        "* **Part 4.5: Automated Coder Application** [[Video]]() [[Notebook]](t81_559_class_04_5_coder.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcAUP0c3hstY"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running and maps Google Drive if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsI496h5hstZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# OpenAI Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain langchain_openai\n",
        "    !wget -q https://raw.githubusercontent.com/jeffheaton/app_generative_ai/main/util_chat.py -O util_chat.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC9A-LaYhsta"
      },
      "source": [
        "# 4.5: Coder Assistant\n",
        "\n",
        "This script builds directly on the **ChatConversation** class you developed earlier, extending it into a structured two-agent workflow. Instead of using a single conversational agent, this design sets up both a **code generator** and a **code reviewer**, each implemented as its own ChatConversation. The generator produces candidate Python code for a defined task (in this case, solving the Traveling Salesman Problem with dynamic programming), while the reviewer evaluates the submission against a strict rubric. This setup allows the two agents to interact iteratively, refining solutions until they either meet the acceptance criteria or the process terminates due to stagnation or iteration limits.\n",
        "\n",
        "At a higher level, the code provides the infrastructure to manage this review loop within a Colab/Jupyter-friendly environment. It handles details like extracting fenced code blocks from model output, repairing syntax if necessary, and enforcing reviewer discipline so that acceptance occurs only when the exact token is returned. With clear logging, persistence of agent state, and flexible configuration, this script demonstrates how the earlier ChatConversation abstraction can be scaled up into a **collaborative system of agents** that generate, critique, and converge on production-ready code.\n",
        "\n",
        "This block centralizes the switches you will most often tweak in Colab/Jupyter to control how the two-agent loop behaves. You **do not** need to change the orchestration code below; instead, adjust these constants to change verbosity, iteration limits, minimum code length checks, persistence, and the default task prompt. The `IPython.display` import is wrapped with a safe fallback so the script can run outside notebooks without errors.\n",
        "\n",
        "**What to modify (typical tweaks):**\n",
        "- `VERBOSE`: Set to `True` to see full generator/reviewer messages during each round. Keep `False` for compact “Iteration N: …” summaries.\n",
        "- `MAX_ROUNDS`: Upper bound on generator↔reviewer iterations. Increase if the reviewer keeps asking for small fixes and you want more chances to converge.\n",
        "- `CODE_MIN_CHARS`: Minimal extracted code length from the model’s fenced block. Raise this if you see trivial stubs; lower it if your tasks are intentionally short.\n",
        "- `SAVE_STATE`: When `True`, each agent persists its memory to disk after revisions. Set `False` for ephemeral runs.\n",
        "- `GENERATOR_STATE_PATH` / `REVIEWER_STATE_PATH`: Filenames for on-disk memory snapshots. Change these if you want separate runs or to avoid overwriting prior state.\n",
        "- `TASK`: Default instruction for the generator. Replace the string to target a different coding task without changing any other part of the script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi6xDqIX3daJ"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from typing import Optional, List, Dict, Any, Tuple\n",
        "import ast\n",
        "import hashlib\n",
        "import html\n",
        "import json\n",
        "import logging\n",
        "import re\n",
        "import textwrap\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from IPython.display import display_markdown  # type: ignore\n",
        "except Exception:\n",
        "    def display_markdown(*args, **kwargs):  # fallback no-op\n",
        "        pass\n",
        "\n",
        "# ============================================================\n",
        "# Notebook constants (tweak here)\n",
        "# ============================================================\n",
        "VERBOSE: bool = False                 # <— set False for concise iteration summaries\n",
        "MAX_ROUNDS: int = 5\n",
        "CODE_MIN_CHARS: int = 120\n",
        "SAVE_STATE: bool = True\n",
        "GENERATOR_STATE_PATH: str = \"generator_mem.json\"\n",
        "REVIEWER_STATE_PATH: str = \"reviewer_mem.json\"\n",
        "\n",
        "# Task can be overridden from a notebook cell if desired\n",
        "TASK = \"provide traveling salesman solution using dynamic programming\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rmxjzEz3jvi"
      },
      "source": [
        "### Reviewer’s Contract and Code-Extraction Rules\n",
        "\n",
        "This block defines exactly **how acceptance is signaled** and **what standards are enforced** during review. The reviewer must return the literal `ACCEPT_TOKEN` string `<<<ACCEPTED>>>` with nothing else when the submission is production-ready. The `RUBRIC` is the reviewer’s checklist: it covers DP correctness (recurrence, base cases, path reconstruction), matching complexity claims, robust edge-case handling, testability, readability, and performance hygiene.\n",
        "\n",
        "To make the pipeline resilient to model formatting quirks, `FENCE_PATTERNS` lists regexes that extract a single Python code block whether the fence is labeled (`python`, `py`) or unlabeled. A `NullHandler` logger is also installed so logging remains silent unless you enable handlers elsewhere. **If you customize anything here**, change `ACCEPT_TOKEN` (and mirror it in the reviewer’s system prompt), refine `RUBRIC` for your domain, or extend `FENCE_PATTERNS` if your model uses unusual fencing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CW4MRdhx6ip"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Task / review config\n",
        "# ============================================================\n",
        "ACCEPT_TOKEN = \"<<<ACCEPTED>>>\"\n",
        "\n",
        "RUBRIC = (\n",
        "    \"Review criteria:\\n\"\n",
        "    \"• Correctness (dynamic programming recurrence, base cases, path reconstruction)\\n\"\n",
        "    \"• Complexity claims match implementation (O(n^2·2^n) time, O(n·2^n) memory)\\n\"\n",
        "    \"• Edge cases (n=0/1, non-square matrix, inf edges)\\n\"\n",
        "    \"• Testability (clear API, deterministic output)\\n\"\n",
        "    \"• Readability (docstring, type hints)\\n\"\n",
        "    \"• Performance (avoid quadratic copies, precompute bitmasks)\\n\"\n",
        ")\n",
        "\n",
        "FENCE_PATTERNS = [\n",
        "    r\"```python\\s*\\n(.*?)```\",\n",
        "    r\"```py\\s*\\n(.*?)```\",\n",
        "    r\"```[a-zA-Z0-9_+\\-]*\\s*\\n(.*?)```\",\n",
        "    r\"```\\s*\\n(.*?)```\",\n",
        "]\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.addHandler(logging.NullHandler())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LiKJYT7zmR9"
      },
      "source": [
        "This section establishes the ground rules for how the reviewer agent will signal acceptance and what standards it should apply. The `ACCEPT_TOKEN` is the **exact string** the reviewer must output when code is considered production-ready—nothing else is allowed. The `RUBRIC` defines the evaluation checklist, covering algorithmic correctness, complexity alignment, edge case handling, API clarity, readability, and efficiency. Together, these constraints enforce discipline on the reviewer so it cannot drift into free-form commentary or generate code itself.\n",
        "\n",
        "Additionally, this block includes regex patterns in `FENCE_PATTERNS` to reliably extract Python code from fenced Markdown blocks, regardless of whether the model labels them as `python`, `py`, or leaves the language tag blank. A lightweight logger is also initialized here, configured with a `NullHandler` so that logging won’t interfere unless explicitly enabled later. These utilities ensure that both the acceptance process and code parsing are strict and deterministic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kIAJNN1yBJR"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Helper utilities\n",
        "# ============================================================\n",
        "def extract_code_from_markdown(text: str, *, min_chars: int = 120) -> str:\n",
        "    for pat in FENCE_PATTERNS:\n",
        "        m = re.search(pat, text, flags=re.DOTALL | re.IGNORECASE)\n",
        "        if m:\n",
        "            code = textwrap.dedent(m.group(1)).strip()\n",
        "            if len(code) >= min_chars:\n",
        "                return code\n",
        "    blocks = re.findall(r\"```(?:[a-zA-Z0-9_+\\-]*)?\\s*\\n(.*?)```\", text, flags=re.DOTALL)\n",
        "    if blocks:\n",
        "        code = textwrap.dedent(\"\\n\\n\".join(b.strip() for b in blocks)).strip()\n",
        "        if len(code) >= min_chars:\n",
        "            return code\n",
        "    return text.strip()\n",
        "\n",
        "def is_valid_python(code: str) -> Tuple[bool, Optional[str]]:\n",
        "    try:\n",
        "        ast.parse(code)\n",
        "        return True, None\n",
        "    except SyntaxError as e:\n",
        "        return False, f\"{e.msg} (line {e.lineno}, col {e.offset})\"\n",
        "\n",
        "def ensure_syntax_or_repair(code: str, generator) -> str:\n",
        "    ok, err = is_valid_python(code)\n",
        "    if ok:\n",
        "        return code\n",
        "    repair_prompt = (\n",
        "        \"The following code has a syntax error.\\n\"\n",
        "        f\"Error: {err}\\n\\n\"\n",
        "        \"Return ONLY a single ```python fenced block with a syntactically valid fix. \"\n",
        "        \"Keep functionality identical where possible.\\n\\n\"\n",
        "        f\"```python\\n{code}\\n```\"\n",
        "    )\n",
        "    repaired = generator.invoke(repair_prompt).content\n",
        "    return extract_code_from_markdown(repaired, min_chars=80)\n",
        "\n",
        "def _digest(s: str) -> str:\n",
        "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def _normalize_accept_text(s: str) -> str:\n",
        "    s = html.unescape(s or \"\").strip()\n",
        "    m = re.fullmatch(r\"```(?:\\w+)?\\s*\\n?(.*?)\\n?```\", s, flags=re.DOTALL)\n",
        "    if m:\n",
        "        s = m.group(1).strip()\n",
        "    if (s.startswith('\"') and s.endswith('\"')) or (s.startswith(\"'\") and s.endswith(\"'\")):\n",
        "        s = s[1:-1].strip()\n",
        "    return s\n",
        "\n",
        "def is_strict_accept(review_text: str, token: str) -> bool:\n",
        "    return _normalize_accept_text(review_text) == token\n",
        "\n",
        "def ask_generator_strict(generator, prompt: str, retries: int = 2, backoff: float = 0.8) -> str:\n",
        "    last_reply = \"\"\n",
        "    for i in range(retries + 1):\n",
        "        last_reply = generator.invoke(prompt).content\n",
        "        code = extract_code_from_markdown(last_reply, min_chars=100)\n",
        "        if code != last_reply or \"```\" in last_reply:\n",
        "            return code\n",
        "        if i < retries:\n",
        "            time.sleep(backoff * (2 ** i))\n",
        "    return extract_code_from_markdown(last_reply, min_chars=80)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "880v75ekzqR-"
      },
      "source": [
        "### Orchestrate the Generator Reviewer Loop\n",
        "\n",
        "The `run_review_loop` function drives the entire two-agent workflow: it prompts the **generator** for code, extracts a fenced Python block, auto-repairs syntax if needed, and then sends that code to the **reviewer** with the formal rubric and acceptance rules. Each iteration prints a compact status line (or full transcripts when `VERBOSE=True`), evaluates whether the reviewer returned the exact `ACCEPT_TOKEN`, and either stops on success or continues with a targeted revision prompt. To avoid wheel-spinning, the loop detects **stagnation** by hashing both the current code and the reviewer’s feedback; if they repeat, the run exits early with a clear reason.\n",
        "\n",
        "You typically won’t modify this function’s logic. Instead, use its keyword arguments—wired to the notebook constants—to tune behavior: `max_rounds` (how many review cycles), `code_min_chars` (minimum code size to accept from the generator), and `save_state` plus the `*_STATE_PATH` settings (to persist each agent’s memory via `.save(...)`). The function ends with a clean **final report** and returns `(final_code, reason)`, so you can programmatically capture the accepted artifact or diagnose why acceptance was not reached.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onbToZ6wyFWz"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Orchestrator\n",
        "# ============================================================\n",
        "def run_review_loop(\n",
        "    code_generator,\n",
        "    code_reviewer,\n",
        "    task: str = TASK,\n",
        "    *,\n",
        "    max_rounds: int = MAX_ROUNDS,\n",
        "    code_min_chars: int = CODE_MIN_CHARS,\n",
        "    save_state: bool = SAVE_STATE,\n",
        "    generator_state_path: str = GENERATOR_STATE_PATH,\n",
        "    reviewer_state_path: str = REVIEWER_STATE_PATH,\n",
        "):\n",
        "    print(\"=== Task ===\")\n",
        "    print(task)\n",
        "    print(\"============\")\n",
        "\n",
        "    gen_prompt = (\n",
        "        f\"Generate Python code to {task}.\\n\"\n",
        "        \"Return ONLY a single fenced block formatted exactly as:\\n\"\n",
        "        \"```python\\n# code here\\n```\\n\"\n",
        "        \"No prose, no explanations.\"\n",
        "    )\n",
        "\n",
        "    # Initial generation\n",
        "    gen_text = code_generator.invoke(gen_prompt).content\n",
        "    code_only = extract_code_from_markdown(gen_text, min_chars=code_min_chars)\n",
        "    code_only = ensure_syntax_or_repair(code_only, code_generator)\n",
        "\n",
        "    if VERBOSE:\n",
        "        print(\"\\n--- Code Generator (raw) ---\\n\")\n",
        "        print(gen_text)\n",
        "        print(\"\\n--- Code Extracted For Review ---\\n\")\n",
        "        print(code_only)\n",
        "    else:\n",
        "        print(\"\\n(Beginning iterations...)\\n\")\n",
        "\n",
        "    last_code_hash = last_review_hash = None\n",
        "    final_reason = None\n",
        "\n",
        "    for round_num in range(1, max_rounds + 1):\n",
        "        review_prompt = (\n",
        "            f\"{RUBRIC}\\n\\n\"\n",
        "            \"Review the following Python code. Do NOT quote or restate these instructions.\\n\"\n",
        "            f\"If the code is production-ready, reply EXACTLY with {ACCEPT_TOKEN} and nothing else.\\n\\n\"\n",
        "            f\"{code_only}\"\n",
        "        )\n",
        "        review_text = code_reviewer.invoke(review_prompt).content\n",
        "\n",
        "        # If reviewer output includes code, force non-accept\n",
        "        if \"```\" in review_text:\n",
        "            review_text += \"\\n\\n(Note: Reviewer included a code block, violating rules. Treating as NOT accepted.)\"\n",
        "\n",
        "        accepted = is_strict_accept(review_text, ACCEPT_TOKEN)\n",
        "\n",
        "        if VERBOSE:\n",
        "            print(f\"\\n--- Code Reviewer (round {round_num}) ---\\n\")\n",
        "            print(review_text)\n",
        "        else:\n",
        "            print(f\"Iteration {round_num}: {'ACCEPTED ✅' if accepted else 'rejected ❌'}\")\n",
        "\n",
        "        if accepted:\n",
        "            final_reason = \"Reviewer accepted the solution.\"\n",
        "            break\n",
        "\n",
        "        # Stagnation detection\n",
        "        code_hash = _digest(code_only)\n",
        "        review_hash = _digest(review_text)\n",
        "        if last_code_hash == code_hash and last_review_hash == review_hash:\n",
        "            final_reason = \"Stagnation detected (same code and same review).\"\n",
        "            break\n",
        "        last_code_hash, last_review_hash = code_hash, review_hash\n",
        "\n",
        "        # Revise based on feedback\n",
        "        revise_prompt = (\n",
        "            \"Reviewer feedback (do NOT include this text in your output):\\n\"\n",
        "            f\"{review_text}\\n\\n\"\n",
        "            \"Apply ONLY the changes requested. Do not modify unrelated code. \"\n",
        "            \"Return ONLY one ```python fenced block.\"\n",
        "        )\n",
        "        gen_text = ask_generator_strict(code_generator, revise_prompt)\n",
        "        code_only = extract_code_from_markdown(gen_text, min_chars=code_min_chars)\n",
        "        code_only = ensure_syntax_or_repair(code_only, code_generator)\n",
        "\n",
        "        if VERBOSE:\n",
        "            print(f\"\\n--- Code Generator (revised raw, round {round_num}) ---\\n\")\n",
        "            print(gen_text)\n",
        "            print(\"\\n--- Code Extracted For Review ---\\n\")\n",
        "            print(code_only)\n",
        "\n",
        "        if save_state:\n",
        "            try:\n",
        "                code_generator.save(generator_state_path)\n",
        "                code_reviewer.save(reviewer_state_path)\n",
        "            except Exception as e:\n",
        "                logger.debug(\"Persistence skipped: %s\", e)\n",
        "    else:\n",
        "        final_reason = \"Loop ended without reviewer acceptance (max rounds).\"\n",
        "\n",
        "    # Final report\n",
        "    print(\"\\n=== Final Result ===\")\n",
        "    print(final_reason or \"(no reason captured)\")\n",
        "    print(\"\\n--- Final Code ---\\n\")\n",
        "    print(code_only)\n",
        "\n",
        "    return code_only, final_reason or \"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6AsU8nt0S8S"
      },
      "source": [
        "### Build the two agents from your existing `ChatConversation`\n",
        "\n",
        "This helper wires up a **code generator** and a **code reviewer** using the `ChatConversation` contract you built earlier—no new agent class required. Each agent gets a focused system prompt: the generator is constrained to emit a single fenced Python block (no prose), and the reviewer is constrained to **never** emit code and to accept only by returning the exact `ACCEPT_TOKEN`. Because both agents conform to the same `.invoke(...)` / `.save(...)` interface, they slot directly into the orchestrator without additional glue code.\n",
        "\n",
        "**What you might customize here:**\n",
        "- `model`: Swap `\"gpt-5-mini\"` for another model you use in your notebook.\n",
        "- `GEN_SYS_PROMPT` / `REVIEWER_SYS_PROMPT`: Tighten or relax guardrails, or tailor to a different domain (e.g., SQL, data viz).\n",
        "- `strategy_name` / `strategy_kwargs`: Adjust your summarization window (`keep_last`, `trigger_len`, `max_summary_chars`) to balance recall vs. token usage.\n",
        "- `temperature`: Use `0.0–0.2` for deterministic generation/reviews, or raise it slightly if the generator needs more exploration.\n",
        "The function returns `(code_generator, code_reviewer)`, ready to pass to `run_review_loop(...)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzDRDn7ZyJZp"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Agent builder (uses your existing ChatConversation)\n",
        "# ============================================================\n",
        "def build_agents():\n",
        "    \"\"\"\n",
        "    Construct the two agents using your existing ChatConversation class contract.\n",
        "    Assumes ChatConversation(model, system_prompt, strategy_name, strategy_kwargs, temperature)\n",
        "    with .invoke(...) and .save(...).\n",
        "    \"\"\"\n",
        "    from util_chat import ChatConversation\n",
        "\n",
        "    GEN_SYS_PROMPT = (\n",
        "        \"You are a coding assistant. Output ONLY Python code.\\n\"\n",
        "        \"Rules:\\n\"\n",
        "        \"1) Return exactly one fenced block:\\n\"\n",
        "        \"```python\\n# optional brief comments\\n# then real code\\n```\\n\"\n",
        "        \"2) No prose outside the fence. If you need to explain, use Python comments at the top of the file.\"\n",
        "    )\n",
        "\n",
        "    REVIEWER_SYS_PROMPT = (\n",
        "        \"You are a strict code reviewer. Do not write or paste code yourself.\\n\"\n",
        "        f\"If the code is production-ready for the stated task, reply with EXACTLY this token and nothing else:\\n{ACCEPT_TOKEN}\\n\"\n",
        "        \"Do not quote or restate the token unless you are accepting. Do not echo any part of the user's prompt.\\n\"\n",
        "        \"Otherwise, identify specific problems and recommended changes in words only. No code blocks.\"\n",
        "    )\n",
        "\n",
        "    code_generator = ChatConversation(\n",
        "        model=\"gpt-5-mini\",\n",
        "        system_prompt=GEN_SYS_PROMPT,\n",
        "        strategy_name=\"summary\",\n",
        "        strategy_kwargs={\"keep_last\": 6, \"trigger_len\": 10, \"max_summary_chars\": 1000},\n",
        "        temperature=0.2,\n",
        "    )\n",
        "\n",
        "    code_reviewer = ChatConversation(\n",
        "        model=\"gpt-5-mini\",\n",
        "        system_prompt=REVIEWER_SYS_PROMPT,\n",
        "        strategy_name=\"summary\",\n",
        "        strategy_kwargs={\"keep_last\": 6, \"trigger_len\": 10, \"max_summary_chars\": 1000},\n",
        "        temperature=0.2,\n",
        "    )\n",
        "\n",
        "    return code_generator, code_reviewer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UncLpBZxyc6"
      },
      "source": [
        "We can now run it and generate code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meuoXx4bEhqY"
      },
      "outputs": [],
      "source": [
        "gen, rev = build_agents()\n",
        "run_review_loop(gen, rev)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11 (genai)",
      "language": "python",
      "name": "genai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}