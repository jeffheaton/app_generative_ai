{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whjsJasuhstV"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_03_2_text_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euOZxlIMhstX"
      },
      "source": [
        "# T81-559: Applications of Generative Artificial Intelligence\n",
        "**Module 3: Large Language Models**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Yov72PhstY"
      },
      "source": [
        "# Module 3 Material\n",
        "\n",
        "* Part 3.1: Foundation Models [[Video]](https://www.youtube.com/watch?v=Gb0tk5qq1fA) [[Notebook]](t81_559_class_03_1_llm.ipynb)\n",
        "* **Part 3.2: Text Generation** [[Video]](https://www.youtube.com/watch?v=lB97Lqt7q58) [[Notebook]](t81_559_class_03_2_text_gen.ipynb)\n",
        "* Part 3.3: Text Summarization [[Video]](https://www.youtube.com/watch?v=3MoIUXE2eEU) [[Notebook]](t81_559_class_03_3_text_summary.ipynb)\n",
        "* Part 3.4: Text Classification [[Video]](https://www.youtube.com/watch?v=2VpOwFIGmA8) [[Notebook]](t81_559_class_03_4_classification.ipynb)\n",
        "* Part 3.5: LLM Writes a Book [[Video]](https://www.youtube.com/watch?v=iU40Rttlb_Q) [[Notebook]](t81_559_class_03_5_book.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcAUP0c3hstY"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running and maps Google Drive if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsI496h5hstZ",
        "outputId": "67eec8fb-44d6-4ffa-b9aa-ee94809bd062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# OpenAI Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC9A-LaYhsta"
      },
      "source": [
        "# 3.2: Text Generation\n",
        "\n",
        "Text generation is one of the most common tasks for LLMs. We've already seen how to use the LLM to generate code; generating regular text for human consumption is similar. To generate text, we will not use a conversational chat style; instead, we will send prompts to LangChain and receive the generated text.\n",
        "\n",
        "We use the following code to query the LLM for text generation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TMF-rtxgRAea"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "from IPython.display import display_markdown\n",
        "\n",
        "MODEL = 'gpt-5-mini'\n",
        "TEMPERATURE = 0.2\n",
        "\n",
        "def get_response(llm, prompt):\n",
        "  messages = [\n",
        "      SystemMessage(\n",
        "          content=\"You are a helpful assistant that answers questions accurately.\"\n",
        "      ),\n",
        "      HumanMessage(content=prompt),\n",
        "  ]\n",
        "\n",
        "  print(\"Model response:\")\n",
        "  output = llm.invoke(messages)\n",
        "  display_markdown(output.content, raw=True)\n",
        "\n",
        "# Initialize the OpenAI LLM with your API key\n",
        "llm = ChatOpenAI(\n",
        "  model=MODEL,\n",
        "  temperature=TEMPERATURE,\n",
        "  n= 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB0IAW8vBJLV"
      },
      "source": [
        "## Text Generation Patterns\n",
        "\n",
        "For simple text generation, you will see several different prompting patterns. These patterns vary depending on the amount of information you provide the LLM. The patterns we will examine in this module are listed here.\n",
        "\n",
        "* Zero-Shot\n",
        "* One-Shot\n",
        "* Few-Shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GeVTcwLl4xi"
      },
      "source": [
        "\n",
        "## Zero-Shot Text Generation\n",
        "\n",
        "A zero-shot prompt for text generation is a method where you provide a language model with a single prompt to generate text, without any prior fine-tuning or specific training on related tasks. To use this approach effectively, you should craft a detailed and clear prompt that communicates exactly what you want the model to generate. Include the type of content, style, and any specific information or constraints that are important to the task. For instance, if you're asking for a business email, you might specify the tone (formal or informal), the main points to cover (meeting time, purpose, attendees), and any call to action. The key is to be explicit about the desired output to guide the model's response accurately, as it relies solely on the information provided in the prompt to produce relevant and coherent text. This method is highly versatile and can be applied across various text generation tasks without the need for customized training.\n",
        "\n",
        "The following text is an example of a zero-shot prompt. I make many requests and provide information about the student, but I do not give the LLM a sample to work from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "bt_Ra8TOw1SP",
        "outputId": "1310124e-9a8b-469e-f25c-a2332e98e5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "I am pleased to write this letter in support of John Smith’s application to your Master’s program in Computer Science. I had the pleasure of teaching John in INFO 558: Applications of Deep Neural Networks at Washington University during the spring 2020 semester. In that course John distinguished himself academically and professionally; he earned an A+ and was consistently among the most thoughtful and engaged students in class.\n\nJohn demonstrated a deep and practical understanding of machine learning and neural network concepts. His coursework and project work showed strong command of both theoretical foundations and hands-on implementation. He consistently produced well-structured, well-documented code and analyses, and he was able to explain complex ideas clearly to his peers. These abilities—technical rigor, clarity of thought, and effective communication—are critical for success in advanced computer science study and research.\n\nBeyond classroom performance, John’s post-graduation accomplishments further underscore his readiness for graduate study in computer science. He graduated with a Master’s in Quantitative Finance (January 2021) with a 3.99 GPA, ranking at the top of his major, and now works as a Senior Financial Risk Analyst at RGA. In that role he develops automation tools and programming solutions for strategic analysis, demonstrating his ability to apply computational methods to real-world, high-stakes problems. His professional experience gives him a mature perspective on system design, software engineering practices, and the value of scalable, robust implementations—skills that will accelerate his progress in a part-time MSCS program while working full time.\n\nJohn is intellectually curious, self-motivated, and disciplined. He balances strong quantitative reasoning with practical engineering instincts, and he learns quickly from feedback. In class he contributed original ideas and constructive critiques in discussions and group work, showing both leadership and collegiality. Given his academic record, technical skillset, and professional experience, I am confident John will excel in rigorous graduate-level coursework and make meaningful contributions to the academic community.\n\nI recommend John Smith without reservation for admission to Georgia Tech’s MS in Computer Science or the University of Pennsylvania’s MCIT program. He has the aptitude, experience, and work ethic to succeed in either program while continuing his professional responsibilities. Please feel free to contact me if you would like any further information about John’s performance or qualifications."
          },
          "metadata": {}
        }
      ],
      "source": [
        "get_response(llm, \"\"\"\n",
        "Generate a positive letter of reccomendation for John Smith, a student of mine\n",
        "for INFO 558 at Washington University, my name is Jeff Heaton. He is applying\n",
        "for a Master of Science in Computer Science. Just give me the\n",
        "body text of the letter, no header or footer. Format in markdown.\n",
        "Below is his request.\n",
        "\n",
        "I hope this message finds you well and that you are enjoying the holiday season!\n",
        "I am John Smith (ID: 1234), a proud alumnus of WashU, having graduated in\n",
        "January 2021 with a Master’s degree in Quantitative Finance.\n",
        "\n",
        "During the spring semester of 2020, I had the pleasure of attending your course,\n",
        "INFO 558: Applications of Deep Neural Networks, which was an elective for my\n",
        "master's program. I thoroughly enjoyed the content and was deeply engaged\n",
        "throughout, culminating in an A+ grade.\n",
        "\n",
        "Since graduating with a 3.99 GPA—top of my major—I have been working as a Senior\n",
        "Financial Risk Analyst at RGA. My role primarily involves developing automation\n",
        "tools and programming for strategic analysis and other analytical tasks. To\n",
        "further enhance my programming skills and knowledge, I am planning to pursue a\n",
        "part-time Master's in Computer Science while continuing to work at RGA.\n",
        "\n",
        "I am a great admirer of your work (I’m a regular viewer of your YouTube channel\n",
        "and have recommended it to my colleagues), and your insights would be invaluable\n",
        "in my application. I am applying to the following programs:\n",
        "\n",
        "Georgia Tech, Master of Science in Computer Science\n",
        "University of Pennsylvania, Master of Computer & Information Technology\n",
        "Could I possibly ask for your support with a recommendation letter for these\n",
        "applications? I have attached my resume for your reference and am happy to\n",
        "provide any additional information you might need.\n",
        "\n",
        "Thank you very much for considering my request. I look forward to your\n",
        "positive response.\n",
        "\n",
        "Warm regards,\n",
        "\n",
        "John\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhpXOo-xOair"
      },
      "source": [
        "## One-Shot Text Generation\n",
        "\n",
        "A one-shot prompt for text generation is a technique where you provide a single, detailed input to a language model to generate text based on that prompt. To use this effectively, start by crafting a clear and concise prompt that includes all necessary details and context needed for the output you desire. Specify the style, tone, and specific elements you want to include. For example, if you want a descriptive paragraph about a seaside town, mention key details like the time of day, the atmosphere, and any particular imagery or emotions you want to evoke. This precision helps the model understand your expectations and produce more relevant and focused content. Once you've prepared your prompt, simply input it into the text generation tool and evaluate the generated text, tweaking your prompt as needed to refine the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "Jc5ICsAUOdm0",
        "outputId": "3ff3fe9e-8899-4b4c-c296-67805b94d8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "I am pleased to recommend John Smith for admission to your Master of Science in Computer Science program. I instructed John in INFO 558: Applications of Deep Neural Networks at Washington University during the Spring 2020 semester, where he earned an A+. Over the course of the semester I had multiple substantive conversations with John about the course material and his research interests, and I was consistently impressed by his technical aptitude, intellectual curiosity, and ability to translate complex ideas into working code.\n\nAlthough John did not come from a traditional computer science background, he quickly demonstrated strong Python programming skills and a solid grasp of contemporary machine learning concepts. In class projects and assignments he not only implemented models effectively but also articulated the underlying assumptions, trade-offs, and evaluation methods. His ability to bridge quantitative finance concepts with machine learning techniques made his work particularly thoughtful and practically oriented.\n\nSince graduating with a Master’s in Quantitative Finance (January 2021) and a 3.99 GPA—top of his major—John has been employed as a Senior Financial Risk Analyst at RGA. In that role he has developed automation tools and analytics used for strategic decision-making. His workplace contributions show he can apply technical skills to real-world problems, write maintainable code, and deliver results under deadlines. These professional experiences, combined with his academic performance, make him well prepared for graduate-level CS coursework while continuing to work.\n\nJohn is self-motivated, a strong communicator, and an effective collaborator. He seeks feedback, iterates on designs, and explains technical choices clearly to both technical and non-technical stakeholders. Given the demands of a part-time master’s while working, these traits are especially important; John has already demonstrated the discipline and organization needed to succeed in such a program.\n\nIn my capacity as VP of Data Science at RGA and as John’s instructor, I can say with confidence that he has the technical foundation, practical experience, and professional maturity to thrive in a Master of Science in Computer Science program. I recommend him without reservation and expect he will be an asset to any graduate program. If you would like further information, I am happy to provide additional details."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(get_response(llm, \"\"\"\n",
        "Generate a positive letter of reccomendation for John Smith, a student of mine\n",
        "for INFO 558 at Washington University, my name is Jeff Heaton. He is applying\n",
        "for a Master of Science in Computer Science. Just give me the\n",
        "body text of the letter, no header or footer. Format in markdown.\n",
        "\n",
        "-----------------\n",
        "This is an example letter of reccomendation, written by me.\n",
        "\n",
        "To Whom It May Concern:\n",
        "John earned an A+ in my course Applications of Deep Neural Networks for the\n",
        "Fall 2019 semester at Washington University in St. Louis. During the semester\n",
        "I got a chance to know John through several discussions, both about my course\n",
        "and his research interests. While John did not come from a computer science\n",
        "background he has demonstrated himself as a capable Python programmer and was\n",
        "able to express his ideas in code.  My primary career is as a VP of data science\n",
        "at RGA, a Fortune 500 insurance company.  In this role I know the value of\n",
        "individuals, such as John, who have a background in finance, understand\n",
        "advanced machine learning topics, and can code sufficiently well to function\n",
        "as a data scientist.\n",
        "\n",
        "-----------\n",
        "The details of this student's request follows.\n",
        "\n",
        "I hope this message finds you well and that you are enjoying the holiday season!\n",
        "I am John Smith (ID: 1234), a proud alumnus of WashU, having graduated in\n",
        "January 2021 with a Master’s degree in Quantitative Finance.\n",
        "\n",
        "During the spring semester of 2020, I had the pleasure of attending your course,\n",
        "INFO 558: Applications of Deep Neural Networks, which was an elective for my\n",
        "master's program. I thoroughly enjoyed the content and was deeply engaged\n",
        "throughout, culminating in an A+ grade.\n",
        "\n",
        "Since graduating with a 3.99 GPA—top of my major—I have been working as a Senior\n",
        "Financial Risk Analyst at RGA. My role primarily involves developing automation\n",
        "tools and programming for strategic analysis and other analytical tasks. To\n",
        "further enhance my programming skills and knowledge, I am planning to pursue a\n",
        "part-time Master's in Computer Science while continuing to work at RGA.\n",
        "\n",
        "I am a great admirer of your work (I’m a regular viewer of your YouTube channel\n",
        "and have recommended it to my colleagues), and your insights would be invaluable\n",
        "in my application. I am applying to the following programs:\n",
        "\n",
        "Georgia Tech, Master of Science in Computer Science\n",
        "University of Pennsylvania, Master of Computer & Information Technology\n",
        "Could I possibly ask for your support with a recommendation letter for these\n",
        "applications? I have attached my resume for your reference and am happy to\n",
        "provide any additional information you might need.\n",
        "\n",
        "Thank you very much for considering my request. I look forward to your\n",
        "positive response.\n",
        "\n",
        "Warm regards,\n",
        "\n",
        "John\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYr9PH7ZOeH3"
      },
      "source": [
        "## Few-Shot Text Generation\n",
        "\n",
        "A few-shot prompt involves presenting a model with a small set of examples to guide its behavior in generating responses or predictions. This technique is particularly useful in machine learning models like language or image generation systems, where the prompt acts as a mini-training session, enabling the model to understand and replicate a desired pattern or style with limited input. For instance, in a text generation model, a few-shot prompt might include a handful of sentences along with the desired outputs, setting the stage for the model to continue producing similar results. This approach helps in refining the model's outputs without the need for extensive training data, making it adaptable and efficient for specific tasks or creative nuances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "uaYfdi_cOkS3",
        "outputId": "1d9a1f9e-9737-4c2d-9232-55631c4d3488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "To Whom It May Concern:\n\nI am pleased to recommend John Smith for admission to your Master of Science in Computer Science program. I had John in my INFO 558: Applications of Deep Neural Networks course at Washington University during the Spring 2020 semester. This is a rigorous, technical graduate course in which students implement deep learning models using Python, TensorFlow, and Keras. John earned an A+ in the course and was consistently among the most capable and thoughtful students in the class.\n\nAlthough John came from a quantitative finance background rather than a formal computer science degree, he demonstrated strong programming ability, rapid mastery of new concepts, and an impressive facility for expressing ideas through code. His assignments and final project showed careful design, clear implementation, and sound experimental methodology. He asked insightful questions in class and in one-on-one discussions that demonstrated both depth of understanding and intellectual curiosity.\n\nSince graduating with a Master’s in Quantitative Finance (January 2021) with a 3.99 GPA—top of his major—John has worked as a Senior Financial Risk Analyst at RGA. In that role he has developed automation tools and analytical software that have meaningfully improved efficiency and decision-making. His professional work complements his academic strengths: he pairs a strong theoretical foundation with practical software engineering skills, and is comfortable taking projects from specification through implementation and validation.\n\nJohn is conscientious, reliable, and collaborative. He communicates technical ideas clearly to both technical and non-technical audiences, manages time well under competing priorities, and welcomes feedback. These attributes, together with his demonstrated programming competence and quantitative background, make him exceptionally well-suited for graduate study in computer science—particularly in programs that emphasize machine learning, systems, or applied algorithms. I believe he will thrive in a part-time MS program while continuing his professional work.\n\nI strongly support John’s application to your program (including the Georgia Tech MSCS and the University of Pennsylvania MCIT, which he has mentioned) and expect he will be an asset to your community. If you would like additional information, I am happy to provide further details about his performance and capabilities.\n\nSincerely,  \nJeff Heaton"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(get_response(llm, \"\"\"\n",
        "Generate a positive letter of reccomendation for John Smith, a student of mine\n",
        "for INFO 558 at Washington University, my name is Jeff Heaton. He is applying\n",
        "for a Master of Science in Computer Science. Just give me the\n",
        "body text of the letter, no header or footer. Format in markdown.\n",
        "\n",
        "-----------------\n",
        "Examples of letters of reccomendation, written by me.\n",
        "\n",
        "To Whom It May Concern:\n",
        "John earned an A+ in my course Applications of Deep Neural Networks for the\n",
        "Fall 2019 semester at Washington University in St. Louis. During the semester\n",
        "I got a chance to know John through several discussions, both about my course\n",
        "and his research interests. While John did not come from a computer science\n",
        "background he has demonstrated himself as a capable Python programmer and was\n",
        "able to express his ideas in code.  My primary career is as a VP of data science\n",
        "at RGA, a Fortune 500 insurance company.  In this role I know the value of\n",
        "individuals, such as John, who have a background in finance, understand\n",
        "advanced machine learning topics, and can code sufficiently well to function\n",
        "as a data scientist.\n",
        "\n",
        "John was a student that in my class, T81-558: Application of Deep Neural Networks,\n",
        "for the Spring 2017 semester. This is a technical graduate class which includes\n",
        "students from the Masters of Science lnformation Systems, Management,\n",
        "computer science, and other disciplines. The course teaches students to\n",
        "implement deep neural networks using Google TensorFlow and Keras in the Python\n",
        "programming language. Students are expected to complete four computer programs\n",
        "and complete a final project. John did well in my course and earned an A+ (4.0).\n",
        "\n",
        "-----------\n",
        "The details of this student's request follows.\n",
        "\n",
        "I hope this message finds you well and that you are enjoying the holiday season!\n",
        "I am John Smith (ID: 1234), a proud alumnus of WashU, having graduated in\n",
        "January 2021 with a Master’s degree in Quantitative Finance.\n",
        "\n",
        "During the spring semester of 2020, I had the pleasure of attending your course,\n",
        "INFO 558: Applications of Deep Neural Networks, which was an elective for my\n",
        "master's program. I thoroughly enjoyed the content and was deeply engaged\n",
        "throughout, culminating in an A+ grade.\n",
        "\n",
        "Since graduating with a 3.99 GPA—top of my major—I have been working as a Senior\n",
        "Financial Risk Analyst at RGA. My role primarily involves developing automation\n",
        "tools and programming for strategic analysis and other analytical tasks. To\n",
        "further enhance my programming skills and knowledge, I am planning to pursue a\n",
        "part-time Master's in Computer Science while continuing to work at RGA.\n",
        "\n",
        "I am a great admirer of your work (I’m a regular viewer of your YouTube channel\n",
        "and have recommended it to my colleagues), and your insights would be invaluable\n",
        "in my application. I am applying to the following programs:\n",
        "\n",
        "Georgia Tech, Master of Science in Computer Science\n",
        "University of Pennsylvania, Master of Computer & Information Technology\n",
        "Could I possibly ask for your support with a recommendation letter for these\n",
        "applications? I have attached my resume for your reference and am happy to\n",
        "provide any additional information you might need.\n",
        "\n",
        "Thank you very much for considering my request. I look forward to your\n",
        "positive response.\n",
        "\n",
        "Warm regards,\n",
        "\n",
        "John\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFDE3DRgHvq1"
      },
      "source": [
        "## Generating Synthetic Data\n",
        "\n",
        "\n",
        "LLMs (Large Language Models) can be leveraged to generate synthetic data, which is particularly valuable for testing various systems, including those requiring personal information or demographic diversity. For example, LLMs can create detailed biographies for random careers, providing realistic and varied data for simulations, testing algorithms, or training AI models. In this instance, synthetic biographies could be generated for a software engineer, a pediatric nurse, a financial analyst, a high school science teacher, and a marketing manager, each featuring unique backgrounds and career trajectories to ensure robust and comprehensive testing scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SRoUOR8eIi07"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "from IPython.display import display_markdown\n",
        "\n",
        "MODEL = 'gpt-5-mini'\n",
        "TEMPERATURE = 0.2\n",
        "\n",
        "def get_response(llm, prompt):\n",
        "  messages = [\n",
        "      SystemMessage(\n",
        "          content=\"\"\"\n",
        "          You are a helpful assistant that generates synthetic data for a person in the career\n",
        "          field you are given. Provide a short bio for the person, not longer than\n",
        "          5 sentences. No markdown. Do not mention the job title specifically.\"\"\"\n",
        "      ),\n",
        "      HumanMessage(content=prompt),\n",
        "  ]\n",
        "\n",
        "  response = llm.invoke(messages)\n",
        "  return response.content\n",
        "\n",
        "# Initialize the OpenAI LLM with your API key\n",
        "llm = ChatOpenAI(\n",
        "  model=MODEL,\n",
        "  temperature=TEMPERATURE,\n",
        "  n= 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdXcz32RODJs"
      },
      "source": [
        "We begin by creating 5 career types we will generate data for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U25feB-bIHSY"
      },
      "outputs": [],
      "source": [
        "CAREER = [\n",
        "    \"software engineer\",\n",
        "    \"pediatric nurse\",\n",
        "    \"financial analyst\",\n",
        "    \"high school science teacher\",\n",
        "    \"marketing manager\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGgajvk9OMy5"
      },
      "source": [
        "We begin by generating a random bio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebMRli43IxVD",
        "outputId": "2a5d5666-b28b-4a0d-ab1b-d1698b1313b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experienced professional with eight years building scalable web services and distributed systems for startups and enterprises. Expert in backend development with Go and Python, frontend work using React, and cloud deployments on AWS and Kubernetes. Regular contributor to open-source projects, advocate for test-driven development and automated CI/CD pipelines, and mentor junior colleagues. Holds a BS in Computer Science and spends weekends cycling and tinkering with home automation.\n"
          ]
        }
      ],
      "source": [
        "print(get_response(llm, \"software engineer\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjLdt7kMOP-Q"
      },
      "source": [
        "Now we generate a CSV file full of these random bios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh4UDM16Jxq7",
        "outputId": "75f8041b-86c1-48c5-90e4-b3e7cbe71805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Careers: 100%|██████████| 50/50 [07:43<00:00,  9.27s/it]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "from tqdm import tqdm  # Progress bar library\n",
        "\n",
        "FILENAME = \"jobs.csv\"\n",
        "\n",
        "# Writing to the CSV file\n",
        "with open(FILENAME, 'w', newline='\\n') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    # Use tqdm to show progress bar\n",
        "    for i in tqdm(range(50), desc=\"Generating Careers\"):\n",
        "      career_choice = random.choice(CAREER)  # Randomly select a career\n",
        "      csvwriter.writerow([i+1, get_response(llm, career_choice)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS4bGv9yOUSH"
      },
      "source": [
        "You can see the generated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-LFTqX3KhFl",
        "outputId": "67a28dc1-f268-4f2c-efcc-6184ff9c6d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,\"With over eight years of experience in hospital and outpatient settings, she specializes in caring for infants, children, and adolescents with both acute and chronic conditions. She holds a BSN and certifications including PALS and BLS, and is experienced with IV therapy, medication administration, and growth and developmental assessments. Fluent in Spanish, she excels at family education, vaccine counseling, and coordinating care with multidisciplinary teams. Known for calm communication and strong advocacy, she mentors new clinicians and leads quality improvement projects to reduce medication errors and improve patient comfort.\"\n",
            "2,\"Alex Rivera is a marketing professional with over eight years of experience leading integrated brand and demand-generation initiatives across technology and consumer goods. Specialties include digital strategy, content marketing, performance analytics, and cross-functional program leadership that have delivered double-digit revenue growth and a 35% lift in qualified leads. Holds an MBA and certifications in Google Analytics and HubSpot; enjoys mentoring junior colleagues and experimenting with emerging martech.\"\n",
            "3,\"Alex Rivera brings 10 years of experience in brand strategy, digital advertising, and demand generation, with a focus on customer acquisition and lifetime value. They lead cross-functional teams to develop data-driven campaigns that combine content, performance marketing, and CRM to boost engagement and revenue while optimizing budgets and analytics. An MBA graduate and frequent industry speaker, Alex mentors creative talent and champions experimentation through A/B testing and marketing automation.\"\n",
            "4,\"Designs and builds scalable backend systems with seven years of experience creating distributed services and RESTful APIs. Proficient in Python, Go, Kubernetes, Docker, and AWS, with a track record of improving system availability and cutting response times by up to 40%. Regularly collaborates with product and QA teams to deliver customer-facing features and mentors junior staff through code reviews and pair programming. Holds a B.S. in Computer Science and contributes to open-source projects focused on observability and performance.\"\n",
            "5,\"Maya Patel has eight years caring for infants, children, and adolescents in both hospital and outpatient settings. She is experienced in medication administration, IV therapy, growth and developmental assessments, family-centered education, and acute care coordination. Maya is certified in pediatric advanced life support and excels at calming families during stressful situations through clear communication and compassionate bedside care. She is committed to injury prevention, childhood wellness education, and improving patient comfort and outcomes.\"\n"
          ]
        }
      ],
      "source": [
        "with open(FILENAME, 'r') as file:\n",
        "    for _ in range(5):\n",
        "        line = file.readline()\n",
        "        if line:\n",
        "            print(line.strip())\n",
        "        else:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auMHm2SZOWgb"
      },
      "source": [
        "We can download the generated CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "IQLZF9qHNZKg",
        "outputId": "1b2cbc7e-8feb-42a9-b35f-323b5f7421d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8cb8e6a3-b0eb-4d73-b71f-600d734e83a3\", \"jobs.csv\", 27166)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(FILENAME)\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11 (genai)",
      "language": "python",
      "name": "genai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}