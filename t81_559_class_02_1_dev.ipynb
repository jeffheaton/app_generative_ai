{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whjsJasuhstV"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_02_1_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euOZxlIMhstX"
      },
      "source": [
        "# T81-559: Applications of Generative Artificial Intelligence\n",
        "**Module 2: Code Generation**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Yov72PhstY"
      },
      "source": [
        "# Module 2 Material\n",
        "\n",
        "* **Part 2.1: Prompting for Code Generation** [[Video]](https://www.youtube.com/watch?v=HVId6kYKKgQ) [[Notebook]](t81_559_class_02_1_dev.ipynb)\n",
        "* Part 2.2: Handling Revision Prompts [[Video]](https://www.youtube.com/watch?v=APpV46tplXA) [[Notebook]](t81_559_class_02_2_multi_prompt.ipynb)\n",
        "* Part 2.3: Using a LLM to Help Debug [[Video]](https://www.youtube.com/watch?v=VPqSNb38QK0) [[Notebook]](t81_559_class_02_3_llm_debug.ipynb)\n",
        "* Part 2.4: Tracking Prompts in Software Development [[Video]](https://www.youtube.com/watch?v=oUFUuYfvXZU) [[Notebook]](t81_559_class_02_4_software_eng.ipynb)\n",
        "* Part 2.5: Limits of LLM Code Generation [[Video]](https://www.youtube.com/watch?v=dKtRI0LZSyY) [[Notebook]](t81_559_class_02_5_code_gen_limits.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcAUP0c3hstY"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running and maps Google Drive if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsI496h5hstZ",
        "outputId": "fa2ccb8d-2bdd-4b2f-9f1f-6d143f351627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.30\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# OpenAI Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC9A-LaYhsta"
      },
      "source": [
        "# 2.1: Prompting for Code Generation\n",
        "\n",
        "## OpenAI for Code Generation\n",
        "\n",
        "LLMs are adept at generating code and can considerably boost programmers' productivity. This technical course requires you to create programs for the assignments. You might wonder if I consider it  \"cheating\" to utilize LLMs to help you write your homework assignments. For this course, I do not consider it cheating to use AI to help you with assignments; I expect such utilization in this course.\n",
        "\n",
        "You can use the same OpenAI LLMs that your OpenAI grants access to for code generation. You also have other options, which may give you access to even greater code generation capabilities, though OpenAI should be sufficient for this class.\n",
        "\n",
        "There are three possible LLM-based code generation tools. All three require additional fees for use.\n",
        "\n",
        "* [GitHub CoPilot](https://github.com/features/copilot)\n",
        "* [ChatGPT](https://chat.openai.com/)\n",
        "* [Amazon CodeWhisperer](https://aws.amazon.com/codewhisperer/)\n",
        "\n",
        "You can use the code below to access OpenAI for code generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TMF-rtxgRAea"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "from IPython.display import display_markdown\n",
        "\n",
        "MODEL = 'gpt-5-mini'\n",
        "\n",
        "def generate_code(prompt):\n",
        "  messages = [\n",
        "      SystemMessage(\n",
        "          content=\"You are a helpful assistant that writes reliable computer program code.\"\n",
        "      ),\n",
        "      HumanMessage(content=prompt),\n",
        "  ]\n",
        "\n",
        "  # Initialize the OpenAI LLM with your API key\n",
        "  llm = ChatOpenAI(\n",
        "    model=MODEL,\n",
        "    temperature= 0.0,\n",
        "    n= 1)\n",
        "\n",
        "  print(MODEL)\n",
        "  print(\"Model response:\")\n",
        "  output = llm.invoke(messages)\n",
        "  display_markdown(output.content,raw=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClPhLkGldhPt"
      },
      "source": [
        "With the above function defined, you can now generate code. The code below generates a Python function to create a Fibonacci sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "ydaqwgRiH4D6",
        "outputId": "5e40dd61-f718-41d5-c69c-3892b290a315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-5-mini\n",
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Here's a simple, safe Python function that returns the first l numbers of the Fibonacci sequence (starting 0, 1, 1, 2, ...). It validates the input and handles l = 0.\n\n```python\ndef fibonacci(l):\n    \"\"\"\n    Return a list of the first l Fibonacci numbers (starting with 0, 1).\n    l must be a non-negative integer.\n\n    Examples:\n    fibonacci(0) -> []\n    fibonacci(1) -> [0]\n    fibonacci(5) -> [0, 1, 1, 2, 3]\n    \"\"\"\n    if not isinstance(l, int):\n        raise TypeError(\"l must be an integer\")\n    if l < 0:\n        raise ValueError(\"l must be non-negative\")\n\n    if l == 0:\n        return []\n    if l == 1:\n        return [0]\n\n    seq = [0, 1]\n    while len(seq) < l:\n        seq.append(seq[-1] + seq[-2])\n    return seq\n\n# Example:\nif __name__ == \"__main__\":\n    print(fibonacci(10))  # -> [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n```\n\nIf you prefer the sequence to start with 1, 1 instead of 0, 1, tell me and I can provide that variant."
          },
          "metadata": {}
        }
      ],
      "source": [
        "generate_code(\"\"\"Write Python code to return a fibonacci sequence of a length specified by the parameter l.\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fzxOCfgeKUF"
      },
      "source": [
        "## Generating Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "priNIsKGgR7M",
        "outputId": "7855723d-6dfe-4a71-a4da-74adaccc54eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-5-mini\n",
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Here is a self-contained Python function that computes an amortization schedule and returns a Pandas DataFrame. It also constructs the column dictionary before creating the DataFrame.\n\n```python\nimport pandas as pd\n\ndef loan_amortization(loan_amount, apr, term):\n    \"\"\"\n    Compute loan amortization schedule.\n\n    Parameters:\n    - loan_amount: float, initial principal amount of the loan.\n    - apr: float, annual percentage rate. Can be given as a decimal (0.05) or percent (5).\n    - term: int, number of months in the loan.\n\n    Returns:\n    - pandas.DataFrame with columns:\n        month     : month number (1..term)\n        amount    : remaining balance after the payment for that month\n        principal : amount applied to principal that month\n        interest  : interest charged that month\n        payment   : total payment that month\n    \"\"\"\n    if term <= 0:\n        raise ValueError(\"term must be a positive integer number of months\")\n    if loan_amount < 0:\n        raise ValueError(\"loan_amount must be non-negative\")\n\n    # Accept APR as percent (e.g. 5) or decimal (0.05)\n    if apr > 1:\n        apr = apr / 100.0\n    monthly_rate = apr / 12.0\n\n    # Calculate fixed monthly payment (handle zero-interest case)\n    if monthly_rate == 0:\n        fixed_payment = loan_amount / term\n    else:\n        r = monthly_rate\n        fixed_payment = r * loan_amount / (1 - (1 + r) ** (-term))\n\n    # prepare column lists\n    months = []\n    amounts = []\n    principals = []\n    interests = []\n    payments = []\n\n    remaining = float(loan_amount)\n\n    for m in range(1, term + 1):\n        months.append(m)\n\n        # interest for this month\n        interest = remaining * monthly_rate\n\n        # principal portion\n        principal = fixed_payment - interest\n\n        # On the final payment, adjust to avoid rounding residuals\n        if m == term:\n            # pay off any remaining balance\n            principal = remaining\n            payment = interest + principal\n        else:\n            payment = fixed_payment\n\n        # subtract principal from remaining balance\n        remaining = remaining - principal\n\n        # rounding to cents for the reported schedule\n        amounts.append(round(max(0.0, remaining), 2))\n        principals.append(round(principal, 2))\n        interests.append(round(interest, 2))\n        payments.append(round(payment, 2))\n\n    # build dictionary of columns\n    columns = {\n        \"month\": months,\n        \"amount\": amounts,\n        \"principal\": principals,\n        \"interest\": interests,\n        \"payment\": payments\n    }\n\n    df = pd.DataFrame(columns)\n    return df\n```\n\nExample usage:\n```\ndf = loan_amortization(10000, 5, 60)   # $10,000 loan, 5% APR, 60 months\nprint(df.head())\n```"
          },
          "metadata": {}
        }
      ],
      "source": [
        "generate_code(\"\"\"\n",
        "Write a Python function named loan_amortization that accepts these parameters.\n",
        "loan_amount - The amount of the loan.\n",
        "apr - The interest rate.\n",
        "term - The number of months in the loan.\n",
        "The function should return a Pandas dataframe that contains the following columns:\n",
        "month - The current month.\n",
        "amount - The amount left on the loan.\n",
        "principal - The amount payed to the principal this month.\n",
        "interest - The amount paid in interest this month.\n",
        "payment - The total payment this month.\n",
        "Additionally, build a dictionary of columns to create the Pandas dataframe.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzhI5nTfgeS4",
        "outputId": "74800518-b774-48d2-f8e7-9814d5be1c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   month        amount   principal    interest     payment\n",
            "0      1  99879.845044  120.154956  416.666667  536.821623\n",
            "1      2  99759.189442  120.655602  416.166021  536.821623\n",
            "2      3  99638.031108  121.158334  415.663289  536.821623\n",
            "3      4  99516.367948  121.663160  415.158463  536.821623\n",
            "4      5  99394.197858  122.170090  414.651533  536.821623\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def loan_amortization(loan_amount, apr, term):\n",
        "    # Convert APR to a monthly interest rate\n",
        "    monthly_interest_rate = apr / 12 / 100\n",
        "\n",
        "    # Calculate monthly payment using the formula for an annuity\n",
        "    payment = loan_amount * (monthly_interest_rate * (1 + monthly_interest_rate) ** term) / ((1 + monthly_interest_rate) ** term - 1)\n",
        "\n",
        "    # Initialize variables\n",
        "    remaining_balance = loan_amount\n",
        "    amortization_schedule = []\n",
        "\n",
        "    # Calculate the schedule\n",
        "    for month in range(1, term + 1):\n",
        "        interest = remaining_balance * monthly_interest_rate\n",
        "        principal = payment - interest\n",
        "        remaining_balance -= principal\n",
        "\n",
        "        # Ensure the last payment does not go negative\n",
        "        if remaining_balance < 0:\n",
        "            principal += remaining_balance\n",
        "            payment = principal + interest\n",
        "            remaining_balance = 0\n",
        "\n",
        "        # Append each month's data to the list\n",
        "        amortization_schedule.append({\n",
        "            \"month\": month,\n",
        "            \"amount\": remaining_balance,\n",
        "            \"principal\": principal,\n",
        "            \"interest\": interest,\n",
        "            \"payment\": payment\n",
        "        })\n",
        "\n",
        "        # Break the loop if balance is zero\n",
        "        if remaining_balance <= 0:\n",
        "            break\n",
        "\n",
        "    # Create a DataFrame from the list of dictionaries\n",
        "    df = pd.DataFrame(amortization_schedule)\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "loan_amount = 100000  # $100,000 loan\n",
        "apr = 5  # 5% annual interest rate\n",
        "term = 360  # 30 years, 360 months\n",
        "\n",
        "df = loan_amortization(loan_amount, apr, term)\n",
        "print(df.head())  # Print the first few rows of the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ZKqu8TeQcm"
      },
      "source": [
        "```\n",
        "Write a Python function named loan_amortization that accepts these parameters.\n",
        "loan_amount - The amount of the loan.\n",
        "apr - The interest rate.\n",
        "term - The number of months in the loan.\n",
        "The function should return a Pandas dataframe that contains the following columns:\n",
        "month - The current month.\n",
        "amount - The amount left on the loan.\n",
        "principal - The amount payed to the principal this month.\n",
        "interest - The amount paid in interest this month.\n",
        "payment - The total payment this month.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t15LDXS9mCI_"
      },
      "source": [
        "## Generating Larger Programs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q2ixb46lmI4Y",
        "outputId": "984dd8c7-8905-4290-ee56-24da51126b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-5-mini\n",
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Here's a complete PyTorch script you can run in a Kaggle notebook. It builds a GPU-enabled regression model (pretrained ResNet18), trains it with early stopping and ReduceLROnPlateau, and writes a submission DataFrame with id and predicted age.\n\nCopy/paste into a Kaggle notebook cell and run. Adjust hyperparameters (batch_size, epochs, lr) if you want.\n\n```\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms, models\n\n# -----------------------\n# Configuration\n# -----------------------\nBASE_DIR = \"/kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age\"\nTRAIN_CSV = os.path.join(BASE_DIR, \"train.csv\")\nTEST_CSV  = os.path.join(BASE_DIR, \"test.csv\")\nIMG_DIR   = BASE_DIR  # images are directly in this folder, filenames in CSV e.g. \"1.jpg\"\n\nSEED = 42\nBATCH_SIZE = 32\nIMG_SIZE = 224\nNUM_WORKERS = 2\nMAX_EPOCHS = 30\nPATIENCE = 5        # early stopping patience (epochs)\nLR = 1e-4\nWEIGHT_DECAY = 1e-4\nMODEL_SAVE_PATH = \"best_model.pth\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# -----------------------\n# Reproducibility\n# -----------------------\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nseed_everything()\n\n# -----------------------\n# Dataset\n# -----------------------\nclass FaceAgeDataset(Dataset):\n    def __init__(self, df, img_dir, transforms=None, is_test=False):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        filename = row['filename']\n        img_path = os.path.join(self.img_dir, filename)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transforms is not None:\n            image = self.transforms(image)\n\n        if self.is_test:\n            # return id to construct submission easily\n            return image, int(row['id'])\n        else:\n            age = float(row['age'])\n            return image, torch.tensor(age, dtype=torch.float32)\n\n# -----------------------\n# Read CSVs\n# -----------------------\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\nprint(\"Train rows:\", len(train_df), \"Test rows:\", len(test_df))\n\n# -----------------------\n# Transforms\n# -----------------------\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ntest_transform = val_transform\n\n# -----------------------\n# Train/Val split\n# -----------------------\nval_fraction = 0.2\nval_len = int(len(train_df) * val_fraction)\ntrain_len = len(train_df) - val_len\ntrain_df_shuffled = train_df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\ntrain_df_part = train_df_shuffled.iloc[:train_len].reset_index(drop=True)\nval_df_part = train_df_shuffled.iloc[train_len:].reset_index(drop=True)\nprint(\"Train split:\", len(train_df_part), \"Val split:\", len(val_df_part))\n\ntrain_dataset = FaceAgeDataset(train_df_part, IMG_DIR, transforms=train_transform, is_test=False)\nval_dataset   = FaceAgeDataset(val_df_part, IMG_DIR, transforms=val_transform, is_test=False)\ntest_dataset  = FaceAgeDataset(test_df, IMG_DIR, transforms=test_transform, is_test=True)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\nval_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n# -----------------------\n# Model\n# -----------------------\ndef build_model(pretrained=True):\n    model = models.resnet18(pretrained=pretrained)\n    num_features = model.fc.in_features\n    model.fc = nn.Linear(num_features, 1)  # regression output\n    return model\n\nmodel = build_model(pretrained=True)\nmodel = model.to(DEVICE)\n\n# -----------------------\n# Loss, Optimizer, Scheduler\n# -----------------------\ncriterion = nn.MSELoss()  # training with MSE; you can also use L1Loss or Huber\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n\n# -----------------------\n# Training loop with early stopping\n# -----------------------\nbest_val_loss = float('inf')\nepochs_no_improve = 0\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    # Train\n    model.train()\n    train_losses = []\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\", leave=False)\n    for images, ages in pbar:\n        images = images.to(DEVICE, non_blocking=True)\n        ages = ages.to(DEVICE, non_blocking=True).unsqueeze(1)  # make shape (N,1)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, ages)\n        loss.backward()\n        optimizer.step()\n\n        train_losses.append(loss.item())\n        pbar.set_postfix({\"loss\": np.mean(train_losses)})\n\n    train_loss = np.mean(train_losses)\n\n    # Validate\n    model.eval()\n    val_losses = []\n    val_mae = []\n    with torch.no_grad():\n        for images, ages in val_loader:\n            images = images.to(DEVICE, non_blocking=True)\n            ages = ages.to(DEVICE, non_blocking=True).unsqueeze(1)\n\n            outputs = model(images)\n            loss = criterion(outputs, ages)\n            val_losses.append(loss.item())\n            mae = torch.abs(outputs - ages).mean().item()\n            val_mae.append(mae)\n\n    val_loss = np.mean(val_losses)\n    val_mae_avg = np.mean(val_mae)\n    scheduler.step(val_loss)\n\n    print(f\"Epoch {epoch}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val MAE {val_mae_avg:.4f}\")\n\n    # Early stopping: save best\n    if val_loss < best_val_loss - 1e-6:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n        print(f\"  New best model saved (val_loss {best_val_loss:.4f}).\")\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n        print(f\"  No improvement for {epochs_no_improve}/{PATIENCE} epochs.\")\n        if epochs_no_improve >= PATIENCE:\n            print(\"Early stopping triggered.\")\n            break\n\n# -----------------------\n# Load best model\n# -----------------------\nif os.path.exists(MODEL_SAVE_PATH):\n    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n    print(\"Loaded best model from\", MODEL_SAVE_PATH)\nelse:\n    print(\"Best model not found, using current model.\")\n\nmodel.eval()\n\n# -----------------------\n# Predict on test set and build submission DataFrame\n# -----------------------\npreds = []\nids = []\n\nwith torch.no_grad():\n    for images, id_batch in tqdm(test_loader, desc=\"Predicting\"):\n        images = images.to(DEVICE, non_blocking=True)\n        outputs = model(images)  # shape (N,1)\n        outputs = outputs.detach().cpu().squeeze(1).numpy()\n        preds.extend(outputs.tolist())\n        ids.extend([int(x) for x in id_batch])\n\n# Convert predictions to non-negative ages and reasonable floats\npreds = np.array(preds)\npreds = np.clip(preds, 0, 120)  # clip to [0,120] rational bounds\n\nsubmission_df = pd.DataFrame({'id': ids, 'age': preds})\n# Ensure order matches test CSV order (sort by id if necessary)\nsubmission_df = submission_df.set_index('id').reindex(test_df['id']).reset_index()\nprint(\"Submission example:\")\nprint(submission_df.head())\n\n# Save to CSV\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission.csv\")\n```\n\nNotes:\n- Uses a pretrained ResNet18; you can switch to a larger architecture (ResNet50, EfficientNet) if you need better accuracy but be mindful of GPU memory.\n- Loss uses MSE; during evaluation I print MAE (mean absolute error) because it's intuitive for age predictions. You could also train with MAE (L1Loss) or Huber for robustness.\n- Early stopping and ReduceLROnPlateau are used. Increase MAX_EPOCHS and PATIENCE if you'd like longer training.\n- The script clips predictions to [0,120] to avoid negative outputs — adjust as desired.\n- The resulting submission.csv will contain two columns: id and age (float)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "generate_code(\"\"\"\n",
        "Create a PyTorch GPU-enabled neural network for a Kaggle competition that asks me to predict the age of people in provided images.\n",
        "The images are stored at this path: /kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age.\n",
        "The training data is in the file: /kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/train.csv.\n",
        "The training data has 3 columns, id, filename, and age. The field age is the target, to be predicted, numeric age in years of\n",
        "the person. The file contains the filename of the image that corresponds to each row, the images are named 1.jpg, 2.jpg, etc,\n",
        "which corresponds to both the id and the filename fields. There is also a test dataset that we must generate a submission\n",
        "dataframe for. The test data is in the file /kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/test.csv,\n",
        "and has the id and filename columns, but we need to generate a submit dataframe with just id and age(the prediction). Train the neural network, use early stopping and generate the submit dataframe.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TjZs_TRht1n"
      },
      "source": [
        "# Module 2 Assignment\n",
        "\n",
        "You can find the first assignment here: [assignment 2](https://github.com/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class2.ipynb)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11 (genai)",
      "language": "python",
      "name": "genai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}