{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whjsJasuhstV"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_02_3_llm_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euOZxlIMhstX"
      },
      "source": [
        "# T81-559: Applications of Generative Artificial Intelligence\n",
        "**Module 2: Code Generation**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Yov72PhstY"
      },
      "source": [
        "# Module 2 Material\n",
        "\n",
        "* Part 2.1: Prompting for Code Generation [[Video]](https://www.youtube.com/watch?v=HVId6kYKKgQ) [[Notebook]](t81_559_class_02_1_dev.ipynb)\n",
        "* Part 2.2: Handling Revision Prompts [[Video]](https://www.youtube.com/watch?v=APpV46tplXA) [[Notebook]](t81_559_class_02_2_multi_prompt.ipynb)\n",
        "* **Part 2.3: Using a LLM to Help Debug** [[Video]](https://www.youtube.com/watch?v=VPqSNb38QK0) [[Notebook]](t81_559_class_02_3_llm_debug.ipynb)\n",
        "* Part 2.4: Tracking Prompts in Software Development [[Video]](https://www.youtube.com/watch?v=oUFUuYfvXZU) [[Notebook]](t81_559_class_02_4_software_eng.ipynb)\n",
        "* Part 2.5: Limits of LLM Code Generation [[Video]](https://www.youtube.com/watch?v=dKtRI0LZSyY) [[Notebook]](t81_559_class_02_5_code_gen_limits.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcAUP0c3hstY"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running and maps Google Drive if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsI496h5hstZ",
        "outputId": "4d3d0be1-71cc-4049-db9a-1a1d2fe22ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.30\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# OpenAI Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC9A-LaYhsta"
      },
      "source": [
        "# 2.3: Using a LLM to Help Debug\n",
        "\n",
        "LLMs can help you debug both the code you create and the code you generate to fulfill your requests. In this part, you will see how to use an LLM as an assistant to help debug a Python program.\n",
        "\n",
        "## Conversational Code Generation\n",
        "\n",
        "We will continue to use the conversational code generation function provided in Module 2.2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TMF-rtxgRAea"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from IPython.display import display_markdown\n",
        "\n",
        "MODEL = \"gpt-5-mini\"\n",
        "SYSTEM_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an\n",
        "AI to generate Python code. If you have notes about the code, place them before\n",
        "the code. Any notes about execution should follow the code. If you do mix any\n",
        "notes with the code, make them comments. Add proper comments to the code.\n",
        "Sort imports and follow PEP 8 formatting.\n",
        "\"\"\"\n",
        "\n",
        "_histories = {}\n",
        "def _get_history(session_id: str):\n",
        "    return _histories.setdefault(session_id, InMemoryChatMessageHistory())\n",
        "\n",
        "def _build_chain():\n",
        "    llm = ChatOpenAI(model=MODEL, temperature=0.0, n=1)\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", SYSTEM_TEMPLATE),\n",
        "        MessagesPlaceholder(\"history\"),\n",
        "        (\"human\", \"{input}\")\n",
        "    ])\n",
        "    return prompt | llm | StrOutputParser()\n",
        "\n",
        "def start_conversation(session_id: str = \"default\"):\n",
        "    base = _build_chain()\n",
        "    with_history = RunnableWithMessageHistory(\n",
        "        base,\n",
        "        lambda sid: _get_history(sid),\n",
        "        input_messages_key=\"input\",\n",
        "        history_messages_key=\"history\",\n",
        "    )\n",
        "    # Return a runnable pre-bound to the session id\n",
        "    return with_history.with_config(configurable={\"session_id\": session_id})\n",
        "\n",
        "def generate_code(conversation, prompt: str):\n",
        "    print(\"Model response:\")\n",
        "    result = conversation.invoke({\"input\": prompt})\n",
        "    display_markdown(result, raw=True)\n",
        "    return result\n",
        "\n",
        "# Usage:\n",
        "# conversation = start_conversation()  # or start_conversation(\"my-session\")\n",
        "# generate_code(conversation, \"Write a function to compute Levenshtein distance.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClPhLkGldhPt"
      },
      "source": [
        "## A Buggy Pi Approximator\n",
        "\n",
        "To see an example of how you can make use of LLM-enabled debugging, consider the following code to use the [Monte Carlo](https://en.wikipedia.org/wiki/Monte_Carlo_method) method to estimate [Pi](https://en.wikipedia.org/wiki/Pi). We need to fix several issues with this code. We can request the LLM to help us debug. This code, when executed, produces the following error:\n",
        "\n",
        "```\n",
        "NameError: name 'xrange' is not defined\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "ydaqwgRiH4D6",
        "outputId": "dfb0754f-828e-4ef3-9121-0c3db92944c5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'xrange' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3436315284.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m  \u001b[0;31m# Number of random points to generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mapproximated_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonte_carlo_pi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Approximated Pi with {num_samples} samples: {approximated_pi}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3436315284.py\u001b[0m in \u001b[0;36mmonte_carlo_pi\u001b[0;34m(num_samples)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minside_circle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Generate random point (x, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def monte_carlo_pi(num_samples):\n",
        "    inside_circle = 0\n",
        "\n",
        "    for _ in xrange(num_samples):\n",
        "        x, y = random.random(), random.random()  # Generate random point (x, y)\n",
        "        if x*2 + y*2 <= 1:\n",
        "            inside_circle += 1  # Check if the point is inside the quarter circle\n",
        "\n",
        "    pi_approximation = 4 * inside_circle / num_samples  # Calculate approximation of Pi\n",
        "    return pi_approximation\n",
        "\n",
        "# Example usage\n",
        "num_samples = 1000000  # Number of random points to generate\n",
        "approximated_pi = monte_carlo_pi(num_samples)\n",
        "print(f\"Approximated Pi with {num_samples} samples: {approximated_pi}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKC-7gT-caaQ"
      },
      "source": [
        "When we ask the LLM to help us debug this code, we should provide as much detail as possible. I usually like to produce a prompt in the following format:\n",
        "\n",
        "```\n",
        "I am trying to debug the following code:\n",
        "\n",
        "... provide code here...\n",
        "\n",
        "However, I am getting the following error:\n",
        "\n",
        "... add the error here, provide stack trace ...\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lqnDZhc4OVU6",
        "outputId": "b2017197-47a5-4b67-d0ec-a796ce227a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Notes about the bug and fixes\n- Problem 1: xrange is a Python 2 function; in Python 3 you should use range().\n- Problem 2: The inside-circle test used x*2 + y*2 which is arithmetic (2*x + 2*y). It should be x**2 + y**2 to test distance from origin.\n- I also added basic input validation and a small main guard for example usage.\n\n# Corrected code\n\n```python\n# Monte Carlo Pi approximation\n# - Uses random sampling in the unit square [0, 1) x [0, 1)\n# - Counts points inside the quarter circle of radius 1 (x**2 + y**2 <= 1)\n# - Pi is approximated as 4 * (points_inside / total_points)\n\nimport math\nimport random\n\n\ndef monte_carlo_pi(num_samples: int) -> float:\n    \"\"\"Approximate Pi using the Monte Carlo method.\n\n    Args:\n        num_samples: Number of random samples to draw. Must be a positive integer.\n\n    Returns:\n        Approximation of Pi as a float.\n\n    Raises:\n        ValueError: If num_samples is not a positive integer.\n    \"\"\"\n    if not isinstance(num_samples, int) or num_samples <= 0:\n        raise ValueError(\"num_samples must be a positive integer\")\n\n    inside_circle = 0\n\n    # Use range() in Python 3. Generate random (x, y) in [0, 1) and\n    # test whether x**2 + y**2 <= 1 (quarter circle of radius 1).\n    for _ in range(num_samples):\n        x = random.random()\n        y = random.random()\n        if x * x + y * y <= 1.0:\n            inside_circle += 1\n\n    # Multiply by 4 because we're sampling a unit square covering a quarter circle.\n    pi_approximation = 4.0 * inside_circle / num_samples\n    return pi_approximation\n\n\nif __name__ == \"__main__\":\n    # Example usage\n    num_samples = 1_000_000  # Number of random points to generate\n    approximated_pi = monte_carlo_pi(num_samples)\n    print(f\"Approximated Pi with {num_samples} samples: {approximated_pi}\")\n    print(f\"math.pi = {math.pi}\")\n```\n\nNotes about execution\n- Run with Python 3 (python3 script.py or in an interactive environment).\n- Result is a stochastic approximation; increasing num_samples improves accuracy but costs more time.\n- For much faster and more accurate results, consider vectorized sampling with numpy (e.g., generate arrays of random numbers and compute distances in bulk)."
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Notes about the bug and fixes\\n- Problem 1: xrange is a Python 2 function; in Python 3 you should use range().\\n- Problem 2: The inside-circle test used x*2 + y*2 which is arithmetic (2*x + 2*y). It should be x**2 + y**2 to test distance from origin.\\n- I also added basic input validation and a small main guard for example usage.\\n\\n# Corrected code\\n\\n```python\\n# Monte Carlo Pi approximation\\n# - Uses random sampling in the unit square [0, 1) x [0, 1)\\n# - Counts points inside the quarter circle of radius 1 (x**2 + y**2 <= 1)\\n# - Pi is approximated as 4 * (points_inside / total_points)\\n\\nimport math\\nimport random\\n\\n\\ndef monte_carlo_pi(num_samples: int) -> float:\\n    \"\"\"Approximate Pi using the Monte Carlo method.\\n\\n    Args:\\n        num_samples: Number of random samples to draw. Must be a positive integer.\\n\\n    Returns:\\n        Approximation of Pi as a float.\\n\\n    Raises:\\n        ValueError: If num_samples is not a positive integer.\\n    \"\"\"\\n    if not isinstance(num_samples, int) or num_samples <= 0:\\n        raise ValueError(\"num_samples must be a positive integer\")\\n\\n    inside_circle = 0\\n\\n    # Use range() in Python 3. Generate random (x, y) in [0, 1) and\\n    # test whether x**2 + y**2 <= 1 (quarter circle of radius 1).\\n    for _ in range(num_samples):\\n        x = random.random()\\n        y = random.random()\\n        if x * x + y * y <= 1.0:\\n            inside_circle += 1\\n\\n    # Multiply by 4 because we\\'re sampling a unit square covering a quarter circle.\\n    pi_approximation = 4.0 * inside_circle / num_samples\\n    return pi_approximation\\n\\n\\nif __name__ == \"__main__\":\\n    # Example usage\\n    num_samples = 1_000_000  # Number of random points to generate\\n    approximated_pi = monte_carlo_pi(num_samples)\\n    print(f\"Approximated Pi with {num_samples} samples: {approximated_pi}\")\\n    print(f\"math.pi = {math.pi}\")\\n```\\n\\nNotes about execution\\n- Run with Python 3 (python3 script.py or in an interactive environment).\\n- Result is a stochastic approximation; increasing num_samples improves accuracy but costs more time.\\n- For much faster and more accurate results, consider vectorized sampling with numpy (e.g., generate arrays of random numbers and compute distances in bulk).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "conversation = start_conversation()\n",
        "generate_code(conversation, \"\"\"\n",
        "I am trying to debug the following code:\n",
        "\n",
        "import random\n",
        "\n",
        "def monte_carlo_pi(num_samples):\n",
        "    inside_circle = 0\n",
        "\n",
        "    for _ in xrange(num_samples):\n",
        "        x, y = random.random(), random.random()  # Generate random point (x, y)\n",
        "        if x*2 + y*2 <= 1:\n",
        "            inside_circle += 1  # Check if the point is inside the quarter circle\n",
        "\n",
        "    pi_approximation = 4 * inside_circle / num_samples  # Calculate approximation of Pi\n",
        "    return pi_approximation\n",
        "\n",
        "# Example usage\n",
        "num_samples = 1000000  # Number of random points to generate\n",
        "approximated_pi = monte_carlo_pi(num_samples)\n",
        "print(f\"Approximated Pi with {num_samples} samples: {approximated_pi}\")\n",
        "\n",
        "However, I am getting the following error:\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "NameError                                 Traceback (most recent call last)\n",
        "<ipython-input-10-c7b4356f1718> in <cell line: 16>()\n",
        "     14 # Example usage\n",
        "     15 num_samples = 1000000  # Number of random points to generate\n",
        "---> 16 approximated_pi = monte_carlo_pi(num_samples)\n",
        "     17 print(f\"Approximated Pi with {num_samples} samples: {approximated_pi}\")\n",
        "\n",
        "<ipython-input-10-c7b4356f1718> in monte_carlo_pi(num_samples)\n",
        "      4     inside_circle = 0\n",
        "      5\n",
        "----> 6     for _ in xrange(num_samples):\n",
        "      7         x, y = random.random(), random.random()  # Generate random point (x, y)\n",
        "      8         if x*2 + y*2 <= 1:\n",
        "\n",
        "NameError: name 'xrange' is not defined\n",
        "\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbqC15eQecdx"
      },
      "source": [
        "In this case, the LLM decided to be an overachiever because I only asked it about the specific error I was getting. However, the LLM provided me with two issues, one of which was the error I encountered. The LLM identified these two issues:\n",
        "\n",
        "* It looks like you're using Python 3, where xrange has been replaced by range.\n",
        "\n",
        "* Also, there's a mistake in the condition to check if the point is inside the quarter circle. It should be ```x ** 2 + y ** 2 <= 1``` instead ```of x*2 + y*2 <= 1```.\n",
        "\n",
        "The LLM also provided a corrected code for me to copy/paste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7U1Bx3Wbje1"
      },
      "source": [
        "## Testing the Corrected Code\n",
        "\n",
        "Now, we can test the corrected code and see that it works properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdJNKLVhRcD3",
        "outputId": "030ceb97-8b08-432c-b493-eae5aa67cf96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximated Pi with 1000000 samples: 3.140488\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def monte_carlo_pi(num_samples):\n",
        "    \"\"\"\n",
        "    Estimate the value of Pi using the Monte Carlo method.\n",
        "\n",
        "    Args:\n",
        "    num_samples (int): Number of random samples to generate.\n",
        "\n",
        "    Returns:\n",
        "    float: Approximated value of Pi.\n",
        "    \"\"\"\n",
        "    inside_circle = 0\n",
        "\n",
        "    for _ in range(num_samples):  # Use range instead of xrange for Python 3\n",
        "        x, y = random.random(), random.random()  # Generate random point (x, y)\n",
        "        if x**2 + y**2 <= 1:  # Correct formula to check if inside the quarter circle\n",
        "            inside_circle += 1\n",
        "\n",
        "    pi_approximation = 4 * inside_circle / num_samples  # Calculate approximation of Pi\n",
        "    return pi_approximation\n",
        "\n",
        "# Example usage\n",
        "num_samples = 1000000  # Number of random points to generate\n",
        "approximated_pi = monte_carlo_pi(num_samples)\n",
        "print(f\"Approximated Pi with {num_samples} samples: {approximated_pi}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAp8eHrFfVIi"
      },
      "source": [
        "## LLMs Explaining Code\n",
        "\n",
        "LLMs are also very adept at explaining code. As you work through this course, you will see that the assignments use a submission function I named \"submit.\" This submission function uses HTTP and API calling techniques that are not covered by this course. However, if you are interested in what the \"submit\" function does, you can ask the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AsYB3VFkfdi7",
        "outputId": "3ea86374-d8b1-475e-8856-0b331e0955c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Notes\n- Below I explain what the function does step by step, point out bugs/oddities, and suggest fixes and improvements.\n- I include a tiny corrected code snippet to fix the main bug (BytesIO usage) and one suggested improvement (use isinstance). The snippet is short and PEP 8 compliant.\n\nWhat this code does (high level)\n- Provides a submit(data, key, no, source_file=None) function intended to submit an assignment to a remote API.\n- Accepts a list (data) of pandas DataFrames and/or PIL Images, encodes them into base64, attaches the student's source file (a .py or .ipynb) base64-encoded, and POSTs the payload to https://api.heatonresearch.com/assignment-submit with the API key in the header.\n\nParameters\n- data: list of items. The function expects items to be either:\n  - PIL.Image.Image objects (images), or\n  - pandas.DataFrame objects (CSV payload).\n  Other item types are ignored.\n- key: string API key included in the HTTP header 'x-api-key'.\n- no: assignment number (the code expects to format suffix '_class{no}' and check that string is in the source_file name).\n- source_file: path to the student's source file (.py or .ipynb). If running in a script, __file__ will be used unless you’re in a Jupyter notebook (then you must pass source_file explicitly because __file__ is not defined).\n\nStep-by-step behavior\n1. If source_file is None and the global __file__ is not present, the function raises an Exception telling you to provide a filename (this is to support notebooks).\n2. If source_file is None but __file__ exists, source_file becomes __file__.\n3. It builds a suffix string '_class{no}' and enforces that suffix appears in the provided source_file path; if not, raises an Exception. This enforces filename convention (e.g., file must contain \"_class1\").\n4. It opens the source_file in binary mode, reads it, and base64-encodes the entire file contents into encoded_python.\n5. It checks the file extension and requires it to be .ipynb or .py, otherwise raises an Exception.\n6. It builds a payload list. For each item in data:\n   - If the item is a PIL image, it saves the image into a BytesIO buffer as PNG, base64-encodes the PNG bytes, and appends a dict {'PNG': <base64-string>} to payload.\n   - If the item is a pandas DataFrame, it converts it to CSV text with to_csv(index=False), encodes that to ASCII bytes, base64-encodes, and appends {'CSV': <base64-string>} to payload.\n7. It POSTs a JSON body containing payload, assignment number, extension, and the base64-encoded source file under key 'py' to the remote endpoint. The API key is sent via an HTTP header 'x-api-key'.\n8. If the response status code is 200 it prints \"Success: <response-text>\", otherwise prints \"Failure: <response-text>\".\n\nMain bug / issues in the provided code\n- Name/usage bug: The code uses BytesIO() but does not import it or reference it from io. The file had import io at top but uses BytesIO directly (should be io.BytesIO() or from io import BytesIO). This will raise NameError at runtime.\n- Type checks: The code uses `type(item) is PIL.Image.Image` and `type(item) is pd.core.frame.DataFrame`. Using type(...) is brittle; use isinstance(...) instead to allow subclasses and to be more robust (and avoid referencing pd internals).\n- Unused imports: numpy is imported but not used.\n- Security / privacy: The function reads and uploads the full source file and sends it to the remote server — be careful not to leak secrets (like local API keys) in the file or in the key variable logged or printed.\n- Size limits: Large files or large data payloads will produce very large base64 strings; there is no check against payload size.\n- Error handling: The requests.post call has no try/except; connection errors or timeouts will raise exceptions. No timeout is set.\n- Only two item types are handled; other types are silently ignored (no warning).\n- The function posts the encoded source file under key 'py' and also includes ext. The API’s exact expected JSON shape should be confirmed with the API docs.\n\nSuggested fixes and improvements\n- Fix BytesIO usage: use io.BytesIO() or from io import BytesIO.\n- Use isinstance(item, PIL.Image.Image) and isinstance(item, pd.DataFrame).\n- Add try/except around requests.post and specify a timeout.\n- Optionally, validate/limit payload size before sending.\n- Consider returning the parsed JSON result or status code rather than just printing.\n- If you expect other types (e.g., numpy arrays), convert/handle them explicitly or raise a warning/error for unsupported types.\n\nSmall corrected snippet (fixes BytesIO + uses isinstance)\nNotes about the snippet:\n- Shows only the relevant payload construction block, sorted imports and PEP 8 style.\n- Uses io.BytesIO and isinstance.\n\nimport base64\nimport io\nimport os\n\nimport pandas as pd\nimport PIL.Image\nimport requests\n\n# Build payload from data list, encoding images and dataframes as base64.\npayload = []\nfor item in data:\n    if isinstance(item, PIL.Image.Image):\n        buffered = io.BytesIO()\n        item.save(buffered, format=\"PNG\")\n        payload.append({\"PNG\": base64.b64encode(buffered.getvalue()).decode(\"ascii\")})\n    elif isinstance(item, pd.DataFrame):\n        csv_bytes = item.to_csv(index=False).encode(\"ascii\")\n        payload.append({\"CSV\": base64.b64encode(csv_bytes).decode(\"ascii\")})\n\nExecution notes\n- Fix the BytesIO bug and add safe error handling before running.\n- Run in Python 3.\n- Be cautious about uploading sensitive files.\n- If you want, I can provide a fully revised version of the whole submit function with improved error handling, logging, and type checks."
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Notes\\n- Below I explain what the function does step by step, point out bugs/oddities, and suggest fixes and improvements.\\n- I include a tiny corrected code snippet to fix the main bug (BytesIO usage) and one suggested improvement (use isinstance). The snippet is short and PEP 8 compliant.\\n\\nWhat this code does (high level)\\n- Provides a submit(data, key, no, source_file=None) function intended to submit an assignment to a remote API.\\n- Accepts a list (data) of pandas DataFrames and/or PIL Images, encodes them into base64, attaches the student\\'s source file (a .py or .ipynb) base64-encoded, and POSTs the payload to https://api.heatonresearch.com/assignment-submit with the API key in the header.\\n\\nParameters\\n- data: list of items. The function expects items to be either:\\n  - PIL.Image.Image objects (images), or\\n  - pandas.DataFrame objects (CSV payload).\\n  Other item types are ignored.\\n- key: string API key included in the HTTP header \\'x-api-key\\'.\\n- no: assignment number (the code expects to format suffix \\'_class{no}\\' and check that string is in the source_file name).\\n- source_file: path to the student\\'s source file (.py or .ipynb). If running in a script, __file__ will be used unless you’re in a Jupyter notebook (then you must pass source_file explicitly because __file__ is not defined).\\n\\nStep-by-step behavior\\n1. If source_file is None and the global __file__ is not present, the function raises an Exception telling you to provide a filename (this is to support notebooks).\\n2. If source_file is None but __file__ exists, source_file becomes __file__.\\n3. It builds a suffix string \\'_class{no}\\' and enforces that suffix appears in the provided source_file path; if not, raises an Exception. This enforces filename convention (e.g., file must contain \"_class1\").\\n4. It opens the source_file in binary mode, reads it, and base64-encodes the entire file contents into encoded_python.\\n5. It checks the file extension and requires it to be .ipynb or .py, otherwise raises an Exception.\\n6. It builds a payload list. For each item in data:\\n   - If the item is a PIL image, it saves the image into a BytesIO buffer as PNG, base64-encodes the PNG bytes, and appends a dict {\\'PNG\\': <base64-string>} to payload.\\n   - If the item is a pandas DataFrame, it converts it to CSV text with to_csv(index=False), encodes that to ASCII bytes, base64-encodes, and appends {\\'CSV\\': <base64-string>} to payload.\\n7. It POSTs a JSON body containing payload, assignment number, extension, and the base64-encoded source file under key \\'py\\' to the remote endpoint. The API key is sent via an HTTP header \\'x-api-key\\'.\\n8. If the response status code is 200 it prints \"Success: <response-text>\", otherwise prints \"Failure: <response-text>\".\\n\\nMain bug / issues in the provided code\\n- Name/usage bug: The code uses BytesIO() but does not import it or reference it from io. The file had import io at top but uses BytesIO directly (should be io.BytesIO() or from io import BytesIO). This will raise NameError at runtime.\\n- Type checks: The code uses `type(item) is PIL.Image.Image` and `type(item) is pd.core.frame.DataFrame`. Using type(...) is brittle; use isinstance(...) instead to allow subclasses and to be more robust (and avoid referencing pd internals).\\n- Unused imports: numpy is imported but not used.\\n- Security / privacy: The function reads and uploads the full source file and sends it to the remote server — be careful not to leak secrets (like local API keys) in the file or in the key variable logged or printed.\\n- Size limits: Large files or large data payloads will produce very large base64 strings; there is no check against payload size.\\n- Error handling: The requests.post call has no try/except; connection errors or timeouts will raise exceptions. No timeout is set.\\n- Only two item types are handled; other types are silently ignored (no warning).\\n- The function posts the encoded source file under key \\'py\\' and also includes ext. The API’s exact expected JSON shape should be confirmed with the API docs.\\n\\nSuggested fixes and improvements\\n- Fix BytesIO usage: use io.BytesIO() or from io import BytesIO.\\n- Use isinstance(item, PIL.Image.Image) and isinstance(item, pd.DataFrame).\\n- Add try/except around requests.post and specify a timeout.\\n- Optionally, validate/limit payload size before sending.\\n- Consider returning the parsed JSON result or status code rather than just printing.\\n- If you expect other types (e.g., numpy arrays), convert/handle them explicitly or raise a warning/error for unsupported types.\\n\\nSmall corrected snippet (fixes BytesIO + uses isinstance)\\nNotes about the snippet:\\n- Shows only the relevant payload construction block, sorted imports and PEP 8 style.\\n- Uses io.BytesIO and isinstance.\\n\\nimport base64\\nimport io\\nimport os\\n\\nimport pandas as pd\\nimport PIL.Image\\nimport requests\\n\\n# Build payload from data list, encoding images and dataframes as base64.\\npayload = []\\nfor item in data:\\n    if isinstance(item, PIL.Image.Image):\\n        buffered = io.BytesIO()\\n        item.save(buffered, format=\"PNG\")\\n        payload.append({\"PNG\": base64.b64encode(buffered.getvalue()).decode(\"ascii\")})\\n    elif isinstance(item, pd.DataFrame):\\n        csv_bytes = item.to_csv(index=False).encode(\"ascii\")\\n        payload.append({\"CSV\": base64.b64encode(csv_bytes).decode(\"ascii\")})\\n\\nExecution notes\\n- Fix the BytesIO bug and add safe error handling before running.\\n- Run in Python 3.\\n- Be cautious about uploading sensitive files.\\n- If you want, I can provide a fully revised version of the whole submit function with improved error handling, logging, and type checks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Start a new conversation\n",
        "conversation = start_conversation()\n",
        "generate_code(conversation, \"\"\"\n",
        "Could you please explain what the following code does?\n",
        "\n",
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if type(item) is PIL.Image.Image:\n",
        "            buffered = BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif type(item) is pd.core.frame.DataFrame:\n",
        "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code==200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lob7vcRKgF0o"
      },
      "source": [
        "As you can see, the LLM explained my \"submit\" function.\n",
        "\n",
        "## Improving Code with LLMs\n",
        "\n",
        "You can also request that a LLM improve your code. You can mention specific improvements you seek, such as removing unused or redundant imports, sorting the imports, and adhering to PEP-8 for your code formatting. In the following code, I request that the LLM improve my submit function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DV_rh0xpgIyZ",
        "outputId": "e9a1af2b-8105-46e8-c07c-631cc4febe5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Notes about improvements implemented\n- Fixes: use io.BytesIO (was missing), use isinstance(...) instead of type(...) checks.\n- Robustness: validate inputs (types, file existence, assignment suffix), support numpy arrays by converting to images or CSVs, and report ignored/unsupported items.\n- Reliability: add timeout and try/except around network call, return structured result instead of only printing, and log warnings.\n- Safety: warn when source file or payload is large.\n- Style: sorted imports, type hints, docstring, clear comments, and PEP 8 formatting.\n\n# Improved submit function\n\n```python\n# Improved assignment submit utility\n# - Encodes provided pandas DataFrames, PIL Images, or numpy arrays as base64 payloads\n# - Attaches the source .py or .ipynb file (must contain \"_class{no}\" in filename)\n# - Posts the payload to the remote submission endpoint with error handling and timeout\n\nimport base64\nimport io\nimport logging\nimport os\nfrom typing import Any, Dict, List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom PIL import Image\n\n# Configure a simple logger for warnings/info; client code can reconfigure as needed.\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\ndef submit(\n    data: List[Union[pd.DataFrame, Image.Image, np.ndarray]],\n    key: str,\n    no: int,\n    source_file: Optional[str] = None,\n    timeout: int = 10,\n    max_source_bytes: int = 10 * 1024 * 1024,\n) -> Dict[str, Any]:\n    \"\"\"Submit assignment data and source file to the remote API.\n\n    Args:\n        data: List of items to submit. Supported types:\n            - pandas.DataFrame -> encoded as CSV\n            - PIL.Image.Image -> encoded as PNG\n            - numpy.ndarray -> if 2D/3D converted to image (PNG), otherwise converted to CSV\n        key: API key string to send in 'x-api-key' header.\n        no: Assignment number. Source filename must contain \"_class{no}\".\n        source_file: Path to the .py or .ipynb file to upload. If None, uses __file__ if available.\n        timeout: Seconds to wait for the HTTP request.\n        max_source_bytes: Warn if source file (in bytes) exceeds this threshold.\n\n    Returns:\n        A dict with keys:\n            - 'success': bool\n            - 'status_code': int or None\n            - 'response_text': str (server response or error message)\n            - 'ignored_count': int (number of unsupported items)\n            - 'payload_item_count': int\n    \"\"\"\n    # Validate key and assignment number\n    if not isinstance(key, str) or not key.strip():\n        raise ValueError(\"key must be a non-empty string\")\n\n    if not isinstance(no, int) or no <= 0:\n        raise ValueError(\"no (assignment number) must be a positive integer\")\n\n    # Determine source_file\n    if source_file is None:\n        if \"__file__\" not in globals():\n            raise Exception(\n                \"Must specify source_file when running in a Jupyter notebook or interactive session.\"\n            )\n        source_file = __file__\n\n    if not os.path.isfile(source_file):\n        raise FileNotFoundError(f\"Source file not found: {source_file}\")\n\n    # Enforce filename suffix convention\n    suffix = f\"_class{no}\"\n    if suffix not in os.path.basename(source_file):\n        raise Exception(f\"Filename must contain the suffix '{suffix}'\")\n\n    # Read and encode the source file\n    with open(source_file, \"rb\") as f:\n        source_bytes = f.read()\n\n    if len(source_bytes) > max_source_bytes:\n        logger.warning(\n            \"Source file size is %d bytes which exceeds the warning threshold of %d bytes.\",\n            len(source_bytes),\n            max_source_bytes,\n        )\n\n    encoded_python = base64.b64encode(source_bytes).decode(\"ascii\")\n\n    # Check extension\n    ext = os.path.splitext(source_file)[-1].lower()\n    if ext not in [\".ipynb\", \".py\"]:\n        raise Exception(f\"Source file extension {ext} is not supported; must be .py or .ipynb\")\n\n    # Build payload: list of dicts with keys 'PNG' or 'CSV'\n    payload: List[Dict[str, str]] = []\n    ignored_count = 0\n\n    for idx, item in enumerate(data):\n        # PIL images\n        if isinstance(item, Image.Image):\n            buf = io.BytesIO()\n            # Save as PNG into buffer\n            item.save(buf, format=\"PNG\")\n            png_bytes = buf.getvalue()\n            payload.append({\"PNG\": base64.b64encode(png_bytes).decode(\"ascii\")})\n            buf.close()\n            continue\n\n        # pandas DataFrame\n        if isinstance(item, pd.DataFrame):\n            csv_bytes = item.to_csv(index=False).encode(\"utf-8\")\n            payload.append({\"CSV\": base64.b64encode(csv_bytes).decode(\"ascii\")})\n            continue\n\n        # numpy array: convert to image if 2D/3D, else convert to CSV-like text\n        if isinstance(item, np.ndarray):\n            if item.ndim in (2, 3):\n                # Normalize or convert dtype for imagery if necessary\n                arr = item\n                # If boolean or float, try to convert to uint8 appropriately\n                if arr.dtype == np.bool_:\n                    arr = (arr.astype(np.uint8) * 255)\n                elif np.issubdtype(arr.dtype, np.floating):\n                    # scale floats assumed in [0,1] to [0,255], clip to be safe\n                    arr = np.clip(arr * 255.0, 0, 255).astype(np.uint8)\n                else:\n                    # if integer type, ensure uint8 or convert\n                    arr = arr.astype(np.uint8)\n\n                # If grayscale 2D, create Image from mode 'L'\n                try:\n                    img = Image.fromarray(arr)\n                except Exception as e:\n                    logger.warning(\"Failed to convert numpy array at index %d to image: %s\", idx, e)\n                    # Fall back to CSV conversion below\n                else:\n                    buf = io.BytesIO()\n                    img.save(buf, format=\"PNG\")\n                    payload.append({\"PNG\": base64.b64encode(buf.getvalue()).decode(\"ascii\")})\n                    buf.close()\n                    continue\n\n            # Fallback: convert numpy array to CSV (1D or failed image)\n            try:\n                df = pd.DataFrame(item)\n                csv_bytes = df.to_csv(index=False).encode(\"utf-8\")\n                payload.append({\"CSV\": base64.b64encode(csv_bytes).decode(\"ascii\")})\n            except Exception as e:\n                logger.warning(\"Failed to convert numpy array at index %d to CSV: %s\", idx, e)\n                ignored_count += 1\n            continue\n\n        # Unsupported item type\n        logger.warning(\"Ignoring unsupported data item at index %d (type %s)\", idx, type(item))\n        ignored_count += 1\n\n    # Perform POST request with timeout and error handling\n    url = \"https://api.heatonresearch.com/assignment-submit\"\n    headers = {\"x-api-key\": key}\n    body = {\"payload\": payload, \"assignment\": no, \"ext\": ext, \"py\": encoded_python}\n\n    try:\n        resp = requests.post(url, headers=headers, json=body, timeout=timeout)\n    except requests.RequestException as exc:\n        logger.error(\"Network error while submitting assignment: %s\", exc)\n        return {\n            \"success\": False,\n            \"status_code\": None,\n            \"response_text\": str(exc),\n            \"ignored_count\": ignored_count,\n            \"payload_item_count\": len(payload),\n        }\n\n    # Return structured information\n    success = resp.status_code == 200\n    if success:\n        logger.info(\"Submission successful: %s\", resp.text)\n    else:\n        logger.error(\"Submission failed (status %d): %s\", resp.status_code, resp.text)\n\n    return {\n        \"success\": success,\n        \"status_code\": resp.status_code,\n        \"response_text\": resp.text,\n        \"ignored_count\": ignored_count,\n        \"payload_item_count\": len(payload),\n    }\n```\n\nExecution notes\n- Run under Python 3.6+ (typing and f-strings used).\n- If you want only console prints, you can reconfigure the logger with logging.basicConfig(level=logging.INFO).\n- The function returns a dict describing the outcome instead of only printing; client code can inspect this to decide further action.\n- If you prefer stricter behavior, change logger.warning calls into raised Exceptions for unsupported items.\n- If you want additional features (e.g., payload size limit enforcement, progress callbacks, authentication via other methods), tell me and I can add them."
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Notes about improvements implemented\\n- Fixes: use io.BytesIO (was missing), use isinstance(...) instead of type(...) checks.\\n- Robustness: validate inputs (types, file existence, assignment suffix), support numpy arrays by converting to images or CSVs, and report ignored/unsupported items.\\n- Reliability: add timeout and try/except around network call, return structured result instead of only printing, and log warnings.\\n- Safety: warn when source file or payload is large.\\n- Style: sorted imports, type hints, docstring, clear comments, and PEP 8 formatting.\\n\\n# Improved submit function\\n\\n```python\\n# Improved assignment submit utility\\n# - Encodes provided pandas DataFrames, PIL Images, or numpy arrays as base64 payloads\\n# - Attaches the source .py or .ipynb file (must contain \"_class{no}\" in filename)\\n# - Posts the payload to the remote submission endpoint with error handling and timeout\\n\\nimport base64\\nimport io\\nimport logging\\nimport os\\nfrom typing import Any, Dict, List, Optional, Union\\n\\nimport numpy as np\\nimport pandas as pd\\nimport requests\\nfrom PIL import Image\\n\\n# Configure a simple logger for warnings/info; client code can reconfigure as needed.\\nlogging.basicConfig(level=logging.INFO)\\nlogger = logging.getLogger(__name__)\\n\\n\\ndef submit(\\n    data: List[Union[pd.DataFrame, Image.Image, np.ndarray]],\\n    key: str,\\n    no: int,\\n    source_file: Optional[str] = None,\\n    timeout: int = 10,\\n    max_source_bytes: int = 10 * 1024 * 1024,\\n) -> Dict[str, Any]:\\n    \"\"\"Submit assignment data and source file to the remote API.\\n\\n    Args:\\n        data: List of items to submit. Supported types:\\n            - pandas.DataFrame -> encoded as CSV\\n            - PIL.Image.Image -> encoded as PNG\\n            - numpy.ndarray -> if 2D/3D converted to image (PNG), otherwise converted to CSV\\n        key: API key string to send in \\'x-api-key\\' header.\\n        no: Assignment number. Source filename must contain \"_class{no}\".\\n        source_file: Path to the .py or .ipynb file to upload. If None, uses __file__ if available.\\n        timeout: Seconds to wait for the HTTP request.\\n        max_source_bytes: Warn if source file (in bytes) exceeds this threshold.\\n\\n    Returns:\\n        A dict with keys:\\n            - \\'success\\': bool\\n            - \\'status_code\\': int or None\\n            - \\'response_text\\': str (server response or error message)\\n            - \\'ignored_count\\': int (number of unsupported items)\\n            - \\'payload_item_count\\': int\\n    \"\"\"\\n    # Validate key and assignment number\\n    if not isinstance(key, str) or not key.strip():\\n        raise ValueError(\"key must be a non-empty string\")\\n\\n    if not isinstance(no, int) or no <= 0:\\n        raise ValueError(\"no (assignment number) must be a positive integer\")\\n\\n    # Determine source_file\\n    if source_file is None:\\n        if \"__file__\" not in globals():\\n            raise Exception(\\n                \"Must specify source_file when running in a Jupyter notebook or interactive session.\"\\n            )\\n        source_file = __file__\\n\\n    if not os.path.isfile(source_file):\\n        raise FileNotFoundError(f\"Source file not found: {source_file}\")\\n\\n    # Enforce filename suffix convention\\n    suffix = f\"_class{no}\"\\n    if suffix not in os.path.basename(source_file):\\n        raise Exception(f\"Filename must contain the suffix \\'{suffix}\\'\")\\n\\n    # Read and encode the source file\\n    with open(source_file, \"rb\") as f:\\n        source_bytes = f.read()\\n\\n    if len(source_bytes) > max_source_bytes:\\n        logger.warning(\\n            \"Source file size is %d bytes which exceeds the warning threshold of %d bytes.\",\\n            len(source_bytes),\\n            max_source_bytes,\\n        )\\n\\n    encoded_python = base64.b64encode(source_bytes).decode(\"ascii\")\\n\\n    # Check extension\\n    ext = os.path.splitext(source_file)[-1].lower()\\n    if ext not in [\".ipynb\", \".py\"]:\\n        raise Exception(f\"Source file extension {ext} is not supported; must be .py or .ipynb\")\\n\\n    # Build payload: list of dicts with keys \\'PNG\\' or \\'CSV\\'\\n    payload: List[Dict[str, str]] = []\\n    ignored_count = 0\\n\\n    for idx, item in enumerate(data):\\n        # PIL images\\n        if isinstance(item, Image.Image):\\n            buf = io.BytesIO()\\n            # Save as PNG into buffer\\n            item.save(buf, format=\"PNG\")\\n            png_bytes = buf.getvalue()\\n            payload.append({\"PNG\": base64.b64encode(png_bytes).decode(\"ascii\")})\\n            buf.close()\\n            continue\\n\\n        # pandas DataFrame\\n        if isinstance(item, pd.DataFrame):\\n            csv_bytes = item.to_csv(index=False).encode(\"utf-8\")\\n            payload.append({\"CSV\": base64.b64encode(csv_bytes).decode(\"ascii\")})\\n            continue\\n\\n        # numpy array: convert to image if 2D/3D, else convert to CSV-like text\\n        if isinstance(item, np.ndarray):\\n            if item.ndim in (2, 3):\\n                # Normalize or convert dtype for imagery if necessary\\n                arr = item\\n                # If boolean or float, try to convert to uint8 appropriately\\n                if arr.dtype == np.bool_:\\n                    arr = (arr.astype(np.uint8) * 255)\\n                elif np.issubdtype(arr.dtype, np.floating):\\n                    # scale floats assumed in [0,1] to [0,255], clip to be safe\\n                    arr = np.clip(arr * 255.0, 0, 255).astype(np.uint8)\\n                else:\\n                    # if integer type, ensure uint8 or convert\\n                    arr = arr.astype(np.uint8)\\n\\n                # If grayscale 2D, create Image from mode \\'L\\'\\n                try:\\n                    img = Image.fromarray(arr)\\n                except Exception as e:\\n                    logger.warning(\"Failed to convert numpy array at index %d to image: %s\", idx, e)\\n                    # Fall back to CSV conversion below\\n                else:\\n                    buf = io.BytesIO()\\n                    img.save(buf, format=\"PNG\")\\n                    payload.append({\"PNG\": base64.b64encode(buf.getvalue()).decode(\"ascii\")})\\n                    buf.close()\\n                    continue\\n\\n            # Fallback: convert numpy array to CSV (1D or failed image)\\n            try:\\n                df = pd.DataFrame(item)\\n                csv_bytes = df.to_csv(index=False).encode(\"utf-8\")\\n                payload.append({\"CSV\": base64.b64encode(csv_bytes).decode(\"ascii\")})\\n            except Exception as e:\\n                logger.warning(\"Failed to convert numpy array at index %d to CSV: %s\", idx, e)\\n                ignored_count += 1\\n            continue\\n\\n        # Unsupported item type\\n        logger.warning(\"Ignoring unsupported data item at index %d (type %s)\", idx, type(item))\\n        ignored_count += 1\\n\\n    # Perform POST request with timeout and error handling\\n    url = \"https://api.heatonresearch.com/assignment-submit\"\\n    headers = {\"x-api-key\": key}\\n    body = {\"payload\": payload, \"assignment\": no, \"ext\": ext, \"py\": encoded_python}\\n\\n    try:\\n        resp = requests.post(url, headers=headers, json=body, timeout=timeout)\\n    except requests.RequestException as exc:\\n        logger.error(\"Network error while submitting assignment: %s\", exc)\\n        return {\\n            \"success\": False,\\n            \"status_code\": None,\\n            \"response_text\": str(exc),\\n            \"ignored_count\": ignored_count,\\n            \"payload_item_count\": len(payload),\\n        }\\n\\n    # Return structured information\\n    success = resp.status_code == 200\\n    if success:\\n        logger.info(\"Submission successful: %s\", resp.text)\\n    else:\\n        logger.error(\"Submission failed (status %d): %s\", resp.status_code, resp.text)\\n\\n    return {\\n        \"success\": success,\\n        \"status_code\": resp.status_code,\\n        \"response_text\": resp.text,\\n        \"ignored_count\": ignored_count,\\n        \"payload_item_count\": len(payload),\\n    }\\n```\\n\\nExecution notes\\n- Run under Python 3.6+ (typing and f-strings used).\\n- If you want only console prints, you can reconfigure the logger with logging.basicConfig(level=logging.INFO).\\n- The function returns a dict describing the outcome instead of only printing; client code can inspect this to decide further action.\\n- If you prefer stricter behavior, change logger.warning calls into raised Exceptions for unsupported items.\\n- If you want additional features (e.g., payload size limit enforcement, progress callbacks, authentication via other methods), tell me and I can add them.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "conversation = start_conversation()\n",
        "generate_code(conversation, \"\"\"\n",
        "Could you please suggest and implement any improvements to the following code?\n",
        "\n",
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if type(item) is PIL.Image.Image:\n",
        "            buffered = BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif type(item) is pd.core.frame.DataFrame:\n",
        "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code==200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNQv82Bzh4ao"
      },
      "source": [
        "As you can see, the LLM suggested several improvements that I will consider for future versions of this function."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11 (genai)",
      "language": "python",
      "name": "genai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}